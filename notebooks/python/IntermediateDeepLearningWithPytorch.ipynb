{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "395aef8b-70bb-4c97-bd75-46c362e78350",
   "metadata": {},
   "source": [
    "# Chapter 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e457ded-a5f5-4baa-bf33-9f8ac07422ce",
   "metadata": {},
   "source": [
    "## PyTorch and object-oriented programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ead0e090-e804-4f23-a058-700129fdce04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# Object-Oriented Programming (OOP)\n",
    "class BankAccount:\n",
    "    def __init__(self, balance):\n",
    "        self.balance = balance\n",
    "\n",
    "# __init__ is called when BankAccount object is created\n",
    "# balance is the attribute of the BankAccount object\n",
    "account = BankAccount(100)\n",
    "print(account.balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04e329e1-0151-4560-a38c-39062c927d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "# Object-Oriented Programming (OOP)\n",
    "# Methods: Python functions to perform tasks\n",
    "class BankAccount:\n",
    "    # deposit method increases balance\n",
    "    def __init__(self, balance):\n",
    "        self.balance = balance\n",
    "        \n",
    "    def deposit(self, amount):\n",
    "        self.balance += amount\n",
    "\n",
    "account = BankAccount(100)\n",
    "account.deposit(50)\n",
    "print(account.balance)\n",
    "# 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "452e9fcb-e147-4079-a9b4-7999f6ce4c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cff42e1-d2a7-4cb9-8da5-b52b8546b220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57faec22-adff-417d-8e65-addaeba318cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2a0d50f-303f-49b9-a3f3-1947416d2a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c22e2bf-3693-4b0e-b831-6f9250db735a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "249ca6e1-3727-4b80-9dc9-cca89d44c57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Water potability dataset\n",
    "# PyTorch Dataset\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "class WaterDataset(Dataset):\n",
    "    # init: load data, store as numpy array\n",
    "    # super().__init__() ensures\n",
    "    # WaterDataset behaves like torch Dataset\n",
    "    def __init__(self, csv_path):\n",
    "        super().__init__()\n",
    "        df = pd.read_csv(csv_path)\n",
    "        self.data = df.to_numpy()\n",
    "        \n",
    "    # len: return the size of the dataset\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "        \n",
    "    # getitem: take one argument called idx\n",
    "    # and return features and label for a single sample at index idx\n",
    "    def __getitem__(self, idx):\n",
    "        features = self.data[idx, :-1]\n",
    "        label = self.data[idx, -1]\n",
    "        return features, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3889171d-34d8-4e8c-98f7-fbb340628dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch DataLoader\n",
    "dataset_train = WaterDataset(\n",
    "    \"./data/water_potability/water_train.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d5fd723d-8eeb-498b-997a-87ab49d32aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    generator=torch.Generator(device=device),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "17e4959e-7919-4b68-be0f-16addfea738b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: tensor([[0.7486, 0.5194, 0.2412, 0.5090, 0.7967, 0.2523, 0.5996, 0.5558, 0.4704],\n",
      "        [0.4123, 0.4281, 0.4803, 0.6372, 0.5199, 0.3339, 0.4732, 0.4508, 0.6655]],\n",
      "       device='cuda:0', dtype=torch.float64),\n",
      "Labels: tensor([1., 0.], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "features, labels = next(iter(dataloader_train))\n",
    "print(f\"Features: {features},\\nLabels: {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "186f0043-0659-4607-bc0b-664514e76e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Model\n",
    "# Sequential model definition:\n",
    "import torch.nn as nn\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(9, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 1),\n",
    "    nn.Sigmoid(),\n",
    ")\n",
    "\n",
    "# Class-based model definition:\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(9, 16, dtype=torch.float64)\n",
    "        self.fc2 = nn.Linear(16, 8, dtype=torch.float64)\n",
    "        self.fc3 = nn.Linear(8, 1, dtype=torch.float64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = nn.functional.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8d5e90c-da14-46f5-8d8e-7dea9df35675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a62de50f-a2fd-4462-bdf0-2c1e1f2f565f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(net.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78724e7-cebb-471d-9fdd-7ab921ed683a",
   "metadata": {},
   "source": [
    "## Optimizers, training, and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ff47792-6c1d-4846-86dc-301ba0e85112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    for features, labels in dataloader_train:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(features)\n",
    "        loss = criterion(\n",
    "            outputs, labels.view(-1, 1)\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c07f825-7d62-4041-a30d-27089df45878",
   "metadata": {},
   "source": [
    "### Optimizers\n",
    "\n",
    "#### Stochastic Gradient Descent (SGD)\n",
    "```\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "```\n",
    "\n",
    "* Update depends on learning rate\n",
    "* Simple and efficient, for basic models\n",
    "* Rarely used in practice\n",
    "\n",
    "#### Adaptive Gradient (Adagrad)\n",
    "```\n",
    "optimizer = optim.Adagrad(net.parameters(), lr=0.01)\n",
    "```\n",
    "\n",
    "* Adapts learning rate for each parameter\n",
    "* Good for sparse data\n",
    "* May decrease the learning rate too fast\n",
    "\n",
    "#### Root Mean Square Propagation (RMSprop)\n",
    "```\n",
    "optimizer = optim.RMSprop(net.parameters(), lr=0.01)\n",
    "```\n",
    "\n",
    "* Update for each parameter based on the size of its previous gradients\n",
    "\n",
    "#### Adaptive Moment Estimation (Adam)\n",
    "```\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "```\n",
    "\n",
    "* Arguably the most versatile and widely used\n",
    "* RMSprop + gradient momentum\n",
    "* Often used as the go-to optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a2a9096-90f6-44c9-aebd-05ada069e07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch DataLoader\n",
    "dataset_test = WaterDataset(\n",
    "    \"./data/water_potability/water_test.csv\"\n",
    ")\n",
    "from torch.utils.data import DataLoader\n",
    "dataloader_test = DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "generator=torch.Generator(device=device),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8ea551a1-3d28-4830-a620-aeb8448633b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6163021922111511\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "# Set up accuracy metric\n",
    "\n",
    "# Put model in eval mode and iterate over\n",
    "# test data batches with no gradients\n",
    "\n",
    "# Pass data to model to get predicted\n",
    "# probabilities\n",
    "# Compute predicted labels\n",
    "# Update accuracy metric\n",
    "\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "acc = Accuracy(task=\"binary\")\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for features, labels in dataloader_test:\n",
    "        outputs = net(features)\n",
    "        preds = (outputs >= 0.5).float()\n",
    "        acc(preds, labels.view(-1, 1))\n",
    "\n",
    "accuracy = acc.compute()\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed097ea2-2ac6-44b3-b2db-5086ed0dc88e",
   "metadata": {},
   "source": [
    "## Vanishing and exploding gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac059b0d-c051-4b29-b74b-e25e014c7022",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Vanishing gradients\n",
    "Gradients get smaller and smaller during\n",
    "backward pass\n",
    "Earlier layers get small parameter updates\n",
    "Model doesn't learn\n",
    "\n",
    "Exploding gradients\n",
    "Gradients get bigger and bigger\n",
    "Parameter updates are too large\n",
    "Training diverges\n",
    "\n",
    "Solution to unstable gradients\n",
    "1. Proper weights initialization\n",
    "2. Good activations\n",
    "3. Batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d721b6f-53b4-4298-95a7-f42b9a29a121",
   "metadata": {},
   "outputs": [],
   "source": [
    "Weights initialization\n",
    "layer = nn.Linear(8, 1)\n",
    "print(layer.weight)\n",
    "Parameter containing:\n",
    "tensor([[-0.0195,\n",
    "\n",
    "0.0992,\n",
    "\n",
    "0.0391,\n",
    "\n",
    "-0.3386, -0.1892, -0.3170,\n",
    "\n",
    "0.0212,\n",
    "0.2148]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97c9ef6-beb9-41ac-b111-431e786dc726",
   "metadata": {},
   "outputs": [],
   "source": [
    "Weights initialization\n",
    "Good initialization ensures:\n",
    "Variance of layer inputs = variance of layer outputs\n",
    "Variance of gradients the same before and after a layer\n",
    "\n",
    "How to achieve this depends on the activation:\n",
    "For ReLU and similar, we can use He/Kaiming initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb5e149-a270-437a-ad04-75b45aa1fdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Weights initialization\n",
    "import torch.nn.init as init\n",
    "init.kaiming_uniform_(layer.weight)\n",
    "print(layer.weight)\n",
    "Parameter containing:\n",
    "tensor([[-0.3063, -0.2410,\n",
    "\n",
    "0.0588,\n",
    "\n",
    "0.2664,\n",
    "\n",
    "0.0502, -0.0136,\n",
    "\n",
    "0.2274,\n",
    "\n",
    "0.0901]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eacfec6-db6b-4b96-ac54-75d3a65c8c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "He / Kaiming initialization\n",
    "init.kaiming_uniform_(self.fc1.weight)\n",
    "init.kaiming_uniform_(self.fc2.weight)\n",
    "init.kaiming_uniform_(\n",
    "self.fc3.weight,\n",
    "nonlinearity=\"sigmoid\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ee12c0-fa7d-4b15-be3f-fadc92e45e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# He / Kaiming initialization\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "class Net(nn.Module):\n",
    "def __init__(self):\n",
    "\n",
    "def forward(self, x):\n",
    "\n",
    "super().__init__()\n",
    "\n",
    "x = nn.functional.relu(self.fc1(x))\n",
    "\n",
    "self.fc1 = nn.Linear(9, 16)\n",
    "\n",
    "x = nn.functional.relu(self.fc2(x))\n",
    "\n",
    "self.fc2 = nn.Linear(16, 8)\n",
    "\n",
    "x = nn.functional.sigmoid(self.fc3(x))\n",
    "\n",
    "self.fc3 = nn.Linear(8, 1)\n",
    "\n",
    "return x\n",
    "\n",
    "init.kaiming_uniform_(self.fc1.weight)\n",
    "init.kaiming_uniform_(self.fc2.weight)\n",
    "init.kaiming_uniform_(\n",
    "self.fc3.weight,\n",
    "nonlinearity=\"sigmoid\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c1bfa6-97f9-402e-9569-dfc85a7d5eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Activation functions\n",
    "\n",
    "Often used as the default activation\n",
    "\n",
    "nn.functional.elu()\n",
    "\n",
    "nn.functional.relu()\n",
    "\n",
    "Non-zero gradients for negative values helps against dying neurons\n",
    "\n",
    "Zero for negative inputs - dying neurons\n",
    "\n",
    "Average output around zero - helps against\n",
    "vanishing gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bfc2f8-6111-4b37-983d-dbec35e25601",
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch normalization\n",
    "After a layer:\n",
    "1. Normalize the layer's outputs by:\n",
    "Subtracting the mean\n",
    "Dividing by the standard deviation\n",
    "2. Scale and shift normalized outputs using learned parameters\n",
    "Model learns optimal inputs distribution for each layer:\n",
    "Faster loss decrease\n",
    "Helps against unstable gradients\n",
    "\n",
    "Batch normalization\n",
    "class Net(nn.Module):\n",
    "def __init__(self):\n",
    "super().__init__()\n",
    "self.fc1 = nn.Linear(9, 16)\n",
    "self.bn1 = nn.BatchNorm1d(16)\n",
    "...\n",
    "def forward(self, x):\n",
    "x = self.fc1(x)\n",
    "x = self.bn1(x)\n",
    "x = nn.functional.elu(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f963dd-3c18-4570-b6dc-53a1441895e1",
   "metadata": {},
   "source": [
    "# Chapter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bc540f-c712-4115-b2c3-c4a655683fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Handling images\n",
    "with PyTorch\n",
    "I N T E R M E D I AT E D E E P L E A R N I N G W I T H P Y T O R C H\n",
    "\n",
    "Michal Oleszak\n",
    "Machine Learning Engineer\n",
    "\n",
    "Clouds dataset\n",
    "\n",
    "1 https://www.kaggle.com/competitions/cloud-type-classification2/data\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "What is an image?\n",
    "Image consists of pixels (\"picture elements\")\n",
    "Each pixel contains color information\n",
    "Grayscale images: integer in 0 - 255\n",
    "30:\n",
    "\n",
    "Color images: three integers, one for each\n",
    "color channel (Red, Green, Blue)\n",
    "RGB = (52, 171, 235):\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Loading images to PyTorch\n",
    "Desired directory structure:\n",
    "clouds_train\n",
    "- cumulus\n",
    "- 75cbf18.jpg\n",
    "- ...\n",
    "- cumulonimbus\n",
    "- ...\n",
    "clouds_test\n",
    "\n",
    "Main folders: clouds_train and\n",
    "clouds_test\n",
    "\n",
    "Inside each main folder: one folder per\n",
    "category\n",
    "Inside each class folder: image files\n",
    "\n",
    "- cumulus\n",
    "- cumulonimbus\n",
    "- ...\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Loading images to PyTorch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "train_transforms = transforms.Compose([\n",
    "transforms.ToTensor(),\n",
    "transforms.Resize((128, 128)),\n",
    "])\n",
    "dataset_train = ImageFolder(\n",
    "\n",
    "Define transformations:\n",
    "Parse to tensor\n",
    "Resize to 128×128\n",
    "Create dataset passing:\n",
    "Path to data\n",
    "Predefined transformations\n",
    "\n",
    "\"data/clouds_train\",\n",
    "transform=train_transforms,\n",
    ")\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Displaying images\n",
    "dataloader_train = DataLoader(\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset_train,\n",
    "\n",
    "plt.imshow(image)\n",
    "\n",
    "shuffle=True,\n",
    "\n",
    "plt.show()\n",
    "\n",
    "batch_size=1,\n",
    ")\n",
    "image, label = next(iter(dataloader_train))\n",
    "print(image.shape)\n",
    "\n",
    "torch.Size([1, 3, 128, 128])\n",
    "\n",
    "image = image.squeeze().permute(1, 2, 0)\n",
    "print(image.shape)\n",
    "\n",
    "torch.Size([128, 128, 3])\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Data augmentation\n",
    "train_transforms = transforms.Compose([\n",
    "transforms.RandomHorizontalFlip(),\n",
    "transforms.RandomRotation(45),\n",
    "transforms.ToTensor(),\n",
    "transforms.Resize((128, 128)),\n",
    "])\n",
    "dataset_train = ImageFolder(\n",
    "\"data/clouds/train\",\n",
    "transform=train_transforms,\n",
    "\n",
    "Data augmentation: Generating more data by\n",
    "applying random transformations to original\n",
    "images\n",
    "Increase the size and diversity of the\n",
    "training set\n",
    "Improve model robustness\n",
    "Reduce overfitting\n",
    "\n",
    ")\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Let's practice!\n",
    "I N T E R M E D I AT E D E E P L E A R N I N G W I T H P Y T O R C H\n",
    "\n",
    "Convolutional\n",
    "Neural Networks\n",
    "I N T E R M E D I AT E D E E P L E A R N I N G W I T H P Y T O R C H\n",
    "\n",
    "Michal Oleszak\n",
    "Machine Learning Engineer\n",
    "\n",
    "Why not use linear layers?\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Why not use linear layers?\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Why not use linear layers?\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Why not use linear layers?\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Why not use linear layers?\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Why not use linear layers?\n",
    "Linear layers:\n",
    "Slow training\n",
    "Overfitting\n",
    "Don't recognize spatial patterns\n",
    "A better alternative: convolutional layers!\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Convolutional layer\n",
    "Slide filter(s) of parameters over the input\n",
    "At each position, perform convolution\n",
    "Resulting feature map:\n",
    "Preservers spatial patterns from input\n",
    "Uses fewer parameters than linear layer\n",
    "One filter = one feature map\n",
    "Apply activations to feature maps\n",
    "All feature maps combined form the output\n",
    "nn.Conv2d(3, 32, kernel_size=3)\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Convolution\n",
    "1. Compute dot product of input patch and\n",
    "filter\n",
    "Top-left field: 2 × 1 = 2\n",
    "2. Sum the result\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Zero-padding\n",
    "Add a frames of zeros to convolutional\n",
    "layer's input\n",
    "nn.Conv2d(\n",
    "3, 32, kernel_size=3, padding=1\n",
    ")\n",
    "\n",
    "Maintains spatial dimensions of the input\n",
    "and output tensors\n",
    "Ensures border pixels are treated equally to\n",
    "others\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Max Pooling\n",
    "Slide non-overlapping window over input\n",
    "At each position, retain only the maximum\n",
    "value\n",
    "Used after convolutional layers to reduce\n",
    "spatial dimensions\n",
    "nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Convolutional Neural Network\n",
    "class Net(nn.Module):\n",
    "def __init__(self, num_classes):\n",
    "super().__init__()\n",
    "self.feature_extractor = nn.Sequential(\n",
    "nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "nn.ELU(),\n",
    "nn.MaxPool2d(kernel_size=2),\n",
    "nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "nn.ELU(),\n",
    "nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "feature_extractor : (convolution,\n",
    "\n",
    "activation, pooling), repeated twice and\n",
    "flattened\n",
    "classifier : single linear layer\n",
    "forward() : pass input image through\n",
    "\n",
    "feature extractor and classifier\n",
    "\n",
    "nn.Flatten(),\n",
    ")\n",
    "self.classifier = nn.Linear(64*16*16, num_classes)\n",
    "def forward(self, x):\n",
    "x = self.feature_extractor(x)\n",
    "x = self.classifier(x)\n",
    "return x\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Feature extractor output size\n",
    "self.feature_extractor = nn.Sequential(\n",
    "nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "nn.ELU(),\n",
    "nn.MaxPool2d(kernel_size=2),\n",
    "nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "nn.ELU(),\n",
    "nn.MaxPool2d(kernel_size=2),\n",
    "nn.Flatten(),\n",
    ")\n",
    "self.classifier = nn.Linear(64*16*16, num_classes)\n",
    "`\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Feature extractor output size\n",
    "self.feature_extractor = nn.Sequential(\n",
    "nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "nn.ELU(),\n",
    "nn.MaxPool2d(kernel_size=2),\n",
    "nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "nn.ELU(),\n",
    "nn.MaxPool2d(kernel_size=2),\n",
    "nn.Flatten(),\n",
    ")\n",
    "self.classifier = nn.Linear(64*16*16, num_classes)\n",
    "`\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Feature extractor output size\n",
    "self.feature_extractor = nn.Sequential(\n",
    "nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "nn.ELU(),\n",
    "nn.MaxPool2d(kernel_size=2),\n",
    "nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "nn.ELU(),\n",
    "nn.MaxPool2d(kernel_size=2),\n",
    "nn.Flatten(),\n",
    ")\n",
    "self.classifier = nn.Linear(64*16*16, num_classes)\n",
    "`\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Feature extractor output size\n",
    "self.feature_extractor = nn.Sequential(\n",
    "nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "nn.ELU(),\n",
    "nn.MaxPool2d(kernel_size=2),\n",
    "nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "nn.ELU(),\n",
    "nn.MaxPool2d(kernel_size=2),\n",
    "nn.Flatten(),\n",
    ")\n",
    "self.classifier = nn.Linear(64*16*16, num_classes)\n",
    "`\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Feature extractor output size\n",
    "self.feature_extractor = nn.Sequential(\n",
    "nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "nn.ELU(),\n",
    "nn.MaxPool2d(kernel_size=2),\n",
    "nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "nn.ELU(),\n",
    "nn.MaxPool2d(kernel_size=2),\n",
    "nn.Flatten(),\n",
    ")\n",
    "self.classifier = nn.Linear(64*16*16, num_classes)\n",
    "`\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Let's practice!\n",
    "I N T E R M E D I AT E D E E P L E A R N I N G W I T H P Y T O R C H\n",
    "\n",
    "Training image\n",
    "classifiers\n",
    "I N T E R M E D I AT E D E E P L E A R N I N G W I T H P Y T O R C H\n",
    "\n",
    "Michal Oleszak\n",
    "Machine Learning Engineer\n",
    "\n",
    "Data augmentation revisited\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Data augmentation revisited\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "What should not be augmented\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "What should not be augmented\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "What should not be augmented\n",
    "Augmentations can impact the label\n",
    "Whether this is confusing depends on the\n",
    "task\n",
    "Always choose augmentations with the\n",
    "data and task in mind!\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Augmentations for cloud classification\n",
    "Random rotation: expose model to different\n",
    "angles of cloud formations\n",
    "Horizontal flip: simulate different\n",
    "viewpoints of the sky\n",
    "Auto contrast adjustment: simulate\n",
    "different lighting conditions\n",
    "train_transforms = transforms.Compose([\n",
    "transforms.RandomHorizontalFlip(),\n",
    "transforms.RandomRotation(45),\n",
    "transforms.RandomAutocontrast(),\n",
    "transforms.ToTensor(),\n",
    "transforms.Resize((128, 128))\n",
    "])\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Cross-Entropy loss\n",
    "Binary classification: binary cross-entropy (BCE) loss\n",
    "Multi-class classification: cross-entropy loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Image classifier training loop\n",
    "net = Net(num_classes=7)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "for epoch in range(10):\n",
    "for images, labels in dataloader_train:\n",
    "optimizer.zero_grad()\n",
    "outputs = net(images)\n",
    "loss = criterion(outputs, labels)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Let's practice!\n",
    "I N T E R M E D I AT E D E E P L E A R N I N G W I T H P Y T O R C H\n",
    "\n",
    "Evaluating image\n",
    "classifiers\n",
    "I N T E R M E D I AT E D E E P L E A R N I N G W I T H P Y T O R C H\n",
    "\n",
    "Michal Oleszak\n",
    "Machine Learning Engineer\n",
    "\n",
    "Data augmentation at test time\n",
    "Data augmentation for training data:\n",
    "\n",
    "Data augmentation for test data:\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "\n",
    "transforms.RandomHorizontalFlip(),\n",
    "\n",
    "#\n",
    "\n",
    "transforms.RandomRotation(45),\n",
    "\n",
    "# NO DATA AUGMENTATION AT TEST TIME\n",
    "\n",
    "transforms.RandomAutocontrast(),\n",
    "\n",
    "#\n",
    "\n",
    "transforms.ToTensor(),\n",
    "\n",
    "transforms.ToTensor(),\n",
    "\n",
    "transforms.Resize((64, 64)),\n",
    "\n",
    "transforms.Resize((64, 64)),\n",
    "\n",
    "])\n",
    "\n",
    "])\n",
    "\n",
    "dataset_train = ImageFolder(\n",
    "\n",
    "dataset_test = ImageFolder(\n",
    "\n",
    ")\n",
    "\n",
    "\"clouds_train\",\n",
    "\n",
    "\"clouds_test\",\n",
    "\n",
    "transform=train_transforms,\n",
    "\n",
    "transform=test_transforms,\n",
    ")\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Precision & Recall: binary classification\n",
    "In binary classification:\n",
    "Precision: Fraction of correct positive predictions\n",
    "Recall: Fraction of all positive examples correctly predicted\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Precision & Recall: multi-class classification\n",
    "In multi-class classification: separate precision and recall for each class\n",
    "Precision: Fraction of cumulus-predictions that were correct\n",
    "Recall: Fraction of all cumulus examples correctly predicted\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Averaging multi-class metrics\n",
    "With 7 classes, we have 7 precision and 7 recall scores\n",
    "We can analyze them per-class, or aggregate:\n",
    "Micro average: global calculation\n",
    "Macro average: mean of per-class metrics\n",
    "Weighted average: weighted mean of per-class metrics\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Averaging multi-class metrics\n",
    "from torchmetrics import Recall\n",
    "recall_per_class = Recall(task=\"multiclass\", num_classes=7, average=None)\n",
    "recall_micro = Recall(task=\"multiclass\", num_classes=7, average=\"micro\")\n",
    "recall_macro = Recall(task=\"multiclass\", num_classes=7, average=\"macro\")\n",
    "recall_weighted = Recall(task=\"multiclass\", num_classes=7, average=\"weighted\")\n",
    "\n",
    "When to use each:\n",
    "Micro: Imbalanced datasets\n",
    "Macro: Care about performance on small classes\n",
    "Weighted: Consider errors in larger classes as more important\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Evaluation loop\n",
    "from torchmetrics import Precision, Recall\n",
    "metric_precision = Precision(\n",
    "task=\"multiclass\", num_classes=7, average=\"macro\"\n",
    ")\n",
    "metric_recall = Recall(\n",
    "task=\"multiclass\", num_classes=7, average=\"macro\"\n",
    ")\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "for images, labels in dataloader_test:\n",
    "\n",
    "Import and define precision and recall\n",
    "metrics\n",
    "Iterate over test examples with no gradient\n",
    "For each test batch, get model outputs,\n",
    "take most likely class, and pass it to metric\n",
    "functions along with the labels\n",
    "Compute the metrics\n",
    "\n",
    "outputs = net(images)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "_, preds = torch.max(outputs, 1)\n",
    "\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "metric_precision(preds, labels)\n",
    "metric_recall(preds, labels)\n",
    "precision = metric_precision.compute()\n",
    "recall = metric_recall.compute()\n",
    "\n",
    "Precision: 0.7284010648727417\n",
    "Recall: 0.763038694858551\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Analyzing performance per class\n",
    "metric_recall = Recall(\n",
    "task=\"multiclass\", num_classes=7, average=None\n",
    ")\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "for images, labels in dataloader_test:\n",
    "\n",
    "Compute metric with average=None\n",
    "This gives one score per class\n",
    "Dataset 's .class_to_idx attribute maps\n",
    "\n",
    "class names to indices\n",
    "\n",
    "outputs = net(images)\n",
    "_, preds = torch.max(outputs, 1)\n",
    "\n",
    "dataset_test.class_to_idx\n",
    "\n",
    "metric_recall(preds, labels)\n",
    "recall = metric_recall.compute()\n",
    "\n",
    "{'cirriform clouds': 0,\n",
    "'clear sky': 1,\n",
    "\n",
    "print(recall)\n",
    "\n",
    "tensor([0.6364, 1.0000, 0.9091, 0.7917,\n",
    "0.5049, 0.9500, 0.5493],\n",
    "dtype=torch.float32)\n",
    "\n",
    "'cumulonimbus clouds': 2,\n",
    "'cumulus clouds': 3,\n",
    "'high cumuliform clouds': 4,\n",
    "'stratiform clouds': 5,\n",
    "'stratocumulus clouds': 6}\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Analyzing performance per class\n",
    "k = class name, e.g. cirriform clouds\n",
    "\n",
    "{\n",
    "k: recall[v].item()\n",
    "for k, v\n",
    "in dataset_test.class_to_idx.items()\n",
    "}\n",
    "\n",
    "{'cirriform clouds': 0.6363636255264282,\n",
    "\n",
    "v = class index, e.g. 0\n",
    "recall[v] =\n",
    "tensor(0.6364, dtype=torch.float32)\n",
    "recall[v].item() = 0.6364\n",
    "\n",
    "'clear sky': 1.0,\n",
    "'cumulonimbus clouds': 0.9090909361839294,\n",
    "'cumulus clouds': 0.7916666865348816,\n",
    "'high cumuliform clouds': 0.5048543810844421,\n",
    "'stratiform clouds': 0.949999988079071,\n",
    "'stratocumulus clouds': 0.5492957830429077}\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Let's practice!\n",
    "I N T E R M E D I AT E D E E P L E A R N I N G W I T H P Y T O R C H\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ddacf7-1980-465d-b8b2-7354881b9d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e65262e8-fbb3-476f-90d3-4b7e2f18c0ae",
   "metadata": {},
   "source": [
    "# Chapter 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da3486e-a60b-4d22-96d8-8bd6ef009071",
   "metadata": {},
   "outputs": [],
   "source": [
    "Handling sequences\n",
    "with PyTorch\n",
    "I N T E R M E D I AT E D E E P L E A R N I N G W I T H P Y T O R C H\n",
    "\n",
    "Michal Oleszak\n",
    "Machine Learning Engineer\n",
    "\n",
    "Sequential data\n",
    "Ordered in time or space\n",
    "Order of the data points contains\n",
    "dependencies between them\n",
    "Examples of sequential data:\n",
    "Time series\n",
    "Text\n",
    "Audio waves\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Electricity consumption prediction\n",
    "Task: predict future electricity consumption based on past patterns\n",
    "Electricity consumption dataset:\n",
    "timestamp\n",
    "\n",
    "consumption\n",
    "\n",
    "0\n",
    "\n",
    "2011-01-01 00:15:00\n",
    "\n",
    "-0.704319\n",
    "\n",
    "1\n",
    "\n",
    "2011-01-01 00:30:00\n",
    "\n",
    "-0.704319\n",
    "\n",
    "...\n",
    "\n",
    "...\n",
    "\n",
    "140254 2014-12-31 23:45:00\n",
    "\n",
    "-0.095751\n",
    "\n",
    "140255 2015-01-01 00:00:00\n",
    "\n",
    "-0.095751\n",
    "\n",
    "...\n",
    "\n",
    "1 Trindade,Artur. (2015). ElectricityLoadDiagrams20112014. UCI Machine Learning Repository.\n",
    "\n",
    "https://doi.org/10.24432/C58C86.\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Train-test split\n",
    "No random splitting for time series!\n",
    "Look-ahead bias: model has info about the future\n",
    "Solution: split by time\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Creating sequences\n",
    "Sequence length = number of data points in one training example\n",
    "24 × 4 = 96 -> consider last 24 hours\n",
    "Predict single next data point\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Creating sequences in Python\n",
    "import numpy as np\n",
    "def create_sequences(df, seq_length):\n",
    "xs, ys = [], []\n",
    "for i in range(len(df) - seq_length):\n",
    "x = df.iloc[i:(i+seq_length), 1]\n",
    "y = df.iloc[i+seq_length, 1]\n",
    "xs.append(x)\n",
    "ys.append(y)\n",
    "\n",
    "Take data and sequence length as inputs\n",
    "Initialize inputs and targets lists\n",
    "Iterate over data points\n",
    "Define inputs and target\n",
    "Append to pre-initialized lists\n",
    "Return inputs and targets as NumPy arrays\n",
    "\n",
    "return np.array(xs), np.array(ys)\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "TensorDataset\n",
    "Create training examples\n",
    "X_train, y_train = create_sequences(train_data, seq_length)\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "(34944, 96) (34944,)\n",
    "\n",
    "Convert them to a Torch Dataset\n",
    "from torch.utils.data import TensorDataset\n",
    "dataset_train = TensorDataset(\n",
    "torch.from_numpy(X_train).float(),\n",
    "torch.from_numpy(y_train).float(),\n",
    ")\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Applicability to other sequential data\n",
    "Same techniques are applicable to other sequences:\n",
    "Large Language Models\n",
    "Speech recognition\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Let's practice!\n",
    "I N T E R M E D I AT E D E E P L E A R N I N G W I T H P Y T O R C H\n",
    "\n",
    "Recurrent Neural\n",
    "Networks\n",
    "I N T E R M E D I AT E D E E P L E A R N I N G W I T H P Y T O R C H\n",
    "\n",
    "Michal Oleszak\n",
    "Machine Learning Engineer\n",
    "\n",
    "Recurrent neuron\n",
    "Feed-forward networks\n",
    "RNNs: have connections pointing back\n",
    "Recurrent neuron:\n",
    "Input x\n",
    "Output y\n",
    "Hidden state h\n",
    "In PyTorch: nn.RNN()\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Unrolling recurrent neuron through time\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Unrolling recurrent neuron through time\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Unrolling recurrent neuron through time\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Deep RNNs\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Sequence-to-sequence architecture\n",
    "Pass sequence as input, use the entire output sequence\n",
    "Example: Real-time speech recognition\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Sequence-to-vector architecture\n",
    "Pass sequence as input, use only the last output\n",
    "Example: Text topic classification\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Vector-to-sequence architecture\n",
    "Pass single input, use the entire output sequence\n",
    "Example: Text generation\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Encoder-decoder architecture\n",
    "Pass entire input sequence, only then start using output sequence\n",
    "Example: Machine translation\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "RNN in PyTorch\n",
    "class Net(nn.Module):\n",
    "def __init__(self):\n",
    "super().__init__()\n",
    "self.rnn = nn.RNN(\n",
    "input_size=1,\n",
    "hidden_size=32,\n",
    "num_layers=2,\n",
    "batch_first=True,\n",
    ")\n",
    "self.fc = nn.Linear(32, 1)\n",
    "def forward(self, x):\n",
    "h0 = torch.zeros(2, x.size(0), 32)\n",
    "\n",
    "Define model class with __init__ method\n",
    "Define recurrent layer, self.rnn\n",
    "Define linear layer, fc\n",
    "In forward() , initialize first hidden state to\n",
    "zeros\n",
    "Pass input and first hidden state through\n",
    "RNN layer\n",
    "Select last RNN's output and pass it\n",
    "through linear layer\n",
    "\n",
    "out, _ = self.rnn(x, h0)\n",
    "out = self.fc(out[:, -1, :])\n",
    "return out\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Let's practice!\n",
    "I N T E R M E D I AT E D E E P L E A R N I N G W I T H P Y T O R C H\n",
    "\n",
    "LSTM and GRU cells\n",
    "I N T E R M E D I AT E D E E P L E A R N I N G W I T H P Y T O R C H\n",
    "\n",
    "Michal Oleszak\n",
    "Machine Learning Engineer\n",
    "\n",
    "Short-term memory problem\n",
    "RNN cells maintain memory via hidden\n",
    "state\n",
    "This memory is very short-term\n",
    "Two more powerful cells solve the problem:\n",
    "LSTM (Long Short-Term Memory) cell\n",
    "GRU (Gated Recurrent Unit) cell\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "RNN cell\n",
    "Two inputs:\n",
    "current input data x\n",
    "previous hidden state h\n",
    "Two outputs:\n",
    "current output y\n",
    "next hidden state h\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "LSTM cell\n",
    "Three inputs and outputs (two hidden\n",
    "states):\n",
    "h : short-term state\n",
    "c : long-term state\n",
    "\n",
    "Three \"gates\":\n",
    "Forget gate: what to remove from longterm memory\n",
    "Input gate: what to save to long-term\n",
    "memory\n",
    "\n",
    "Outputs h and y are the same\n",
    "\n",
    "Output gate: what to return at the\n",
    "current time step\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "LSTM in PyTorch\n",
    "class Net(nn.Module):\n",
    "def __init__(self, input_size):\n",
    "super().__init__()\n",
    "self.lstm = nn.LSTM(\n",
    "input_size=1,\n",
    "hidden_size=32,\n",
    "num_layers=2,\n",
    "batch_first=True,\n",
    ")\n",
    "\n",
    "__init__() :\n",
    "\n",
    "Replace nn.RNN with nn.LSTM\n",
    "forward() :\n",
    "\n",
    "Add another hidden state c\n",
    "Initialize c and h with zeros\n",
    "Pass both hidden states to lstm layer\n",
    "\n",
    "self.fc = nn.Linear(32, 1)\n",
    "def forward(self, x):\n",
    "h0 = torch.zeros(2, x.size(0), 32)\n",
    "c0 = torch.zeros(2, x.size(0), 32)\n",
    "out, _ = self.lstm(x, (h0, c0))\n",
    "out = self.fc(out[:, -1, :])\n",
    "return out\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "GRU cell\n",
    "Simplified version of LSTM cell\n",
    "Just one hidden state\n",
    "No output gate\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "GRU in PyTorch\n",
    "class Net(nn.Module):\n",
    "def __init__(self, input_size):\n",
    "super().__init__()\n",
    "self.gru = nn.GRU(\n",
    "input_size=1,\n",
    "\n",
    "__init__() :\n",
    "\n",
    "Replace nn.RNN with nn.GRU\n",
    "forward() :\n",
    "\n",
    "Use the gru layer\n",
    "\n",
    "hidden_size=32,\n",
    "num_layers=2,\n",
    "batch_first=True,\n",
    ")\n",
    "self.fc = nn.Linear(32, 1)\n",
    "def forward(self, x):\n",
    "h0 = torch.zeros(2, x.size(0), 32)\n",
    "out, _ = self.gru(x, h0)\n",
    "out = self.fc(out[:, -1, :])\n",
    "return out\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Should I use RNN, LSTM, or GRU?\n",
    "RNN is not used much anymore\n",
    "GRU is simpler than LSTM = less computation\n",
    "Relative performance varies per use-case\n",
    "Try both and compare\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Let's practice!\n",
    "I N T E R M E D I AT E D E E P L E A R N I N G W I T H P Y T O R C H\n",
    "\n",
    "Training and\n",
    "evaluating RNNs\n",
    "I N T E R M E D I AT E D E E P L E A R N I N G W I T H P Y T O R C H\n",
    "\n",
    "Michal Oleszak\n",
    "Machine Learning Engineer\n",
    "\n",
    "Mean Squared Error Loss\n",
    "Error:\n",
    "\n",
    "Squaring the error:\n",
    "\n",
    "prediction − target\n",
    "\n",
    "Ensures positive and negative errors don't\n",
    "cancel out\n",
    "\n",
    "Squared Error:\n",
    "\n",
    "Penalizes large errors more\n",
    "\n",
    "2\n",
    "\n",
    "In PyTorch:\n",
    "\n",
    "(prediction − target)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "Mean Squared Error:\n",
    "\n",
    "2\n",
    "\n",
    "avg[(prediction − target) ]\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Expanding tensors\n",
    "Recurrent layers expect input shape\n",
    "(batch_size, seq_length, num_features)\n",
    "\n",
    "We got (batch_size, seq_length)\n",
    "\n",
    "for seqs, labels in dataloader_train:\n",
    "print(seqs.shape)\n",
    "\n",
    "torch.Size([32, 96])\n",
    "\n",
    "We must add one dimension at the end\n",
    "seqs = seqs.view(32, 96, 1)\n",
    "print(seqs.shape)\n",
    "\n",
    "torch.Size([32, 96, 1])\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Squeezing tensors\n",
    "In evaluation loop, we need to revert the\n",
    "reshaping done in the training loop\n",
    "\n",
    "Shapes of model outputs and labels must\n",
    "match for the loss function\n",
    "\n",
    "Labels are of shape (batch_size)\n",
    "\n",
    "We can drop the last dimension from model\n",
    "outputs\n",
    "\n",
    "for seqs, labels in test_loader:\n",
    "print(labels.shape)\n",
    "torch.Size([32])\n",
    "\n",
    "out = net(seqs).squeeze()\n",
    "torch.Size([32])\n",
    "\n",
    "Model outputs are (batch_size, 1)\n",
    "out = net(seqs)\n",
    "torch.Size([32, 1])\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Training loop\n",
    "net = Net()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(\n",
    "net.parameters(), lr=0.001\n",
    ")\n",
    "\n",
    "Instantiate model, define loss & optimizer\n",
    "Iterate over epochs and data batches\n",
    "Reshape input sequence\n",
    "The rest: as usual\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "for seqs, labels in dataloader_train:\n",
    "seqs = seqs.view(32, 96, 1)\n",
    "outputs = net(seqs)\n",
    "loss = criterion(outputs, labels)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Evaluation loop\n",
    "mse = torchmetrics.MeanSquaredError()\n",
    "\n",
    "Set up MSE metric\n",
    "Iterate through test data with no gradients\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "for seqs, labels in test_loader:\n",
    "\n",
    "Reshape model inputs\n",
    "Squeeze model outputs\n",
    "\n",
    "seqs = seqs.view(32, 96, 1)\n",
    "\n",
    "Update the metric\n",
    "\n",
    "outputs = net(seqs).squeeze()\n",
    "\n",
    "Compute final metric value\n",
    "\n",
    "mse(outputs, labels)\n",
    "print(f\"Test MSE: {mse.compute()}\")\n",
    "Test MSE: 0.13292162120342255\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "LSTM vs. GRU\n",
    "LSTM:\n",
    "Test MSE: 0.13292162120342255\n",
    "\n",
    "GRU:\n",
    "Test MSE: 0.12187089771032333\n",
    "\n",
    "GRU preferred: same or better results with less processing power\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Let's practice!\n",
    "I N T E R M E D I AT E D E E P L E A R N I N G W I T H P Y T O R C H\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5917894a-0dc8-4d69-a280-d730a97265f5",
   "metadata": {},
   "source": [
    "# Chapter 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f558bb5-5101-41be-9c33-4ad4ce2d7035",
   "metadata": {},
   "outputs": [],
   "source": [
    "Multi-input models\n",
    "I N T E R M E D I AT E D E E P L E A R N I N G W I T H P Y T O R C H\n",
    "\n",
    "Michal Oleszak\n",
    "Machine Learning Engineer\n",
    "\n",
    "Why multi-input?\n",
    "Using more information\n",
    "\n",
    "Multi-modal models\n",
    "\n",
    "Metric learning\n",
    "\n",
    "Self-supervised learning\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Omniglot dataset\n",
    "\n",
    "1 Lake, B. M., Salakhutdinov, R., and Tenenbaum, J. B. (2015). Human-level concept learning through probabilistic\n",
    "\n",
    "program induction. Science, 350(6266), 1332-1338.\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Character classification\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Character classification\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Character classification\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Character classification\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Two-input Dataset\n",
    "from PIL import Image\n",
    "\n",
    "Assign samples and transforms\n",
    "\n",
    "class OmniglotDataset(Dataset):\n",
    "\n",
    "print(samples[0])\n",
    "\n",
    "def __init__(self, transform, samples):\n",
    "self.transform = transform\n",
    "self.samples = samples\n",
    "def __len__(self):\n",
    "return len(self.samples)\n",
    "def __getitem__(self, idx):\n",
    "img_path, alphabet, label = self.samples[idx]\n",
    "img = Image.open(img_path).convert('L')\n",
    "img = self.transform(img)\n",
    "return img, alphabet, label\n",
    "\n",
    "[(\n",
    "'omniglot_train/.../0459_14.png',\n",
    "array([1., 0., 0., ..., 0., 0., 0.]),\n",
    "0\n",
    ")]\n",
    "\n",
    "Implement __len__()\n",
    "Load and transform image\n",
    "Return both inputs and label\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Tensor concatenation\n",
    "x = torch.tensor([\n",
    "[1, 2, 3],\n",
    "])\n",
    "y = torch.tensor([\n",
    "[4, 5, 6],\n",
    "])\n",
    "\n",
    "Concatenation along axis 0\n",
    "torch.cat((x, y), dim=0)\n",
    "[[1, 2, 3],\n",
    "[4, 5, 6]]\n",
    "\n",
    "Concatenation along axis 1\n",
    "torch.cat((x, y), dim=1)\n",
    "[[1, 2, 3, 4, 5, 6]]\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Two-input architecture\n",
    "class Net(nn.Module):\n",
    "def __init__(self):\n",
    "super().__init__()\n",
    "self.image_layer = nn.Sequential(\n",
    "nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "\n",
    "Define image processing layer\n",
    "Define alphabet processing layer\n",
    "Define classifier layer\n",
    "\n",
    "nn.MaxPool2d(kernel_size=2),\n",
    "nn.ELU(),\n",
    "nn.Flatten(),\n",
    "nn.Linear(16*32*32, 128)\n",
    ")\n",
    "self.alphabet_layer = nn.Sequential(\n",
    "nn.Linear(30, 8),\n",
    "nn.ELU(),\n",
    ")\n",
    "self.classifier = nn.Sequential(\n",
    "nn.Linear(128 + 8, 964),\n",
    ")\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Two-input architecture\n",
    "def forward(self, x_image, x_alphabet):\n",
    "x_image = self.image_layer(x_image)\n",
    "x_alphabet = self.alphabet_layer(x_alphabet)\n",
    "x = torch.cat((x_image, x_alphabet), dim=1)\n",
    "return self.classifier(x)\n",
    "\n",
    "Pass image through image layer\n",
    "Pass alphabet through alphabet layer\n",
    "Concatenate image and alphabet outputs\n",
    "Pass the result through classifier\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Training loop\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "for epoch in range(10):\n",
    "for img, alpha, labels in dataloader_train:\n",
    "optimizer.zero_grad()\n",
    "\n",
    "Training data consists of three items:\n",
    "Image\n",
    "Alphabet vector\n",
    "Labels\n",
    "We pass the model images and alphabets\n",
    "\n",
    "outputs = net(img, alpha)\n",
    "loss = criterion(outputs, labels)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Let's practice!\n",
    "I N T E R M E D I AT E D E E P L E A R N I N G W I T H P Y T O R C H\n",
    "\n",
    "Multi-output models\n",
    "I N T E R M E D I AT E D E E P L E A R N I N G W I T H P Y T O R C H\n",
    "\n",
    "Michal Oleszak\n",
    "Machine Learning Engineer\n",
    "\n",
    "Why multi-output?\n",
    "Multi-task learning\n",
    "\n",
    "Multi-label classification\n",
    "\n",
    "Regularization\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Character and alphabet classification\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Character and alphabet classification\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Two-output Dataset\n",
    "class OmniglotDataset(Dataset):\n",
    "def __init__(self, transform, samples):\n",
    "self.transform = transform\n",
    "self.samples = samples\n",
    "\n",
    "We can use the same Dataset...\n",
    "...with updated samples:\n",
    "print(samples[0])\n",
    "\n",
    "def __len__(self):\n",
    "return len(self.samples)\n",
    "\n",
    "[(\n",
    "'omniglot_train/.../0459_14.png',\n",
    "\n",
    "def __getitem__(self, idx):\n",
    "img_path, alphabet, label = \\\n",
    "self.samples[idx]\n",
    "\n",
    "0,\n",
    "0,\n",
    ")]\n",
    "\n",
    "img = Image.open(img_path).convert('L')\n",
    "img = self.transform(img)\n",
    "return img, alphabet, label\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Two-output architecture\n",
    "class Net(nn.Module):\n",
    "def __init__(self, num_alpha, num_char):\n",
    "super().__init__()\n",
    "self.image_layer = nn.Sequential(\n",
    "nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "nn.MaxPool2d(kernel_size=2),\n",
    "nn.ELU(),\n",
    "nn.Flatten(),\n",
    "nn.Linear(16*32*32, 128)\n",
    "\n",
    "Define image-processing sub-network\n",
    "Define output-specific classifiers\n",
    "Pass image through dedicated sub-network\n",
    "Pass the result through each output layer\n",
    "Return both outputs\n",
    "\n",
    ")\n",
    "self.classifier_alpha = nn.Linear(128, 30)\n",
    "self.classifier_char = nn.Linear(128, 964)\n",
    "def forward(self, x):\n",
    "x_image = self.image_layer(x)\n",
    "output_alpha = self.classifier_alpha(x_image)\n",
    "output_char = self.classifier_char(x_image)\n",
    "return output_alpha, output_char\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Training loop\n",
    "for epoch in range(10):\n",
    "for images, labels_alpha, labels_char \\\n",
    "in dataloader_train:\n",
    "optimizer.zero_grad()\n",
    "outputs_alpha, outputs_char = net(images)\n",
    "loss_alpha = criterion(\n",
    "\n",
    "Model produces two outputs\n",
    "Calculate loss for each output\n",
    "Combine the losses to one total loss\n",
    "Backprop and optimize with the total loss\n",
    "\n",
    "outputs_alpha, labels_alpha\n",
    ")\n",
    "loss_char = criterion(\n",
    "outputs_char, labels_char\n",
    ")\n",
    "loss = loss_alpha + loss_char\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Let's practice!\n",
    "I N T E R M E D I AT E D E E P L E A R N I N G W I T H P Y T O R C H\n",
    "\n",
    "Evaluation of multioutput models and\n",
    "loss weighting\n",
    "I N T E R M E D I AT E D E E P L E A R N I N G W I T H P Y T O R C H\n",
    "\n",
    "Michal Oleszak\n",
    "Machine Learning Engineer\n",
    "\n",
    "Model evaluation\n",
    "acc_alpha = Accuracy(\n",
    "task=\"multiclass\", num_classes=30\n",
    ")\n",
    "acc_char = Accuracy(\n",
    "task=\"multiclass\", num_classes=964\n",
    ")\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "for images, labels_alpha, labels_char \\\n",
    "in dataloader_test:\n",
    "\n",
    "Set up metric for each output\n",
    "Iterate over test loader and get outputs\n",
    "Calculate prediction for each output\n",
    "Update accuracy metrics\n",
    "Calculate final accuracy scores\n",
    "print(f\"Alphabet: {acc_alpha.compute()}\")\n",
    "print(f\"Character: {acc_char.compute()}\")\n",
    "\n",
    "out_alpha, out_char = net(images)\n",
    "_, pred_alpha = torch.max(out_alpha, 1)\n",
    "\n",
    "Alphabet: 0.3166305720806122\n",
    "\n",
    "_, pred_char = torch.max(out_char, 1)\n",
    "\n",
    "Character: 0.24064336717128754\n",
    "\n",
    "acc_alpha(pred_alpha, labels_alpha)\n",
    "acc_char(pred_char, labels_char)\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Multi-output training loop revisited\n",
    "for epoch in range(10):\n",
    "for images, labels_alpha, labels_char \\\n",
    "in dataloader_train:\n",
    "\n",
    "Two losses: for alphabets and characters\n",
    "Final loss defined as sum of alphabet and\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "character losses:\n",
    "\n",
    "outputs_alpha, outputs_char = net(images)\n",
    "\n",
    "loss = loss_alpha + loss_char\n",
    "\n",
    "loss_alpha = criterion(\n",
    "outputs_alpha, labels_alpha\n",
    ")\n",
    "\n",
    "Both classification tasks deemed equally\n",
    "important\n",
    "\n",
    "loss_char = criterion(\n",
    "outputs_char, labels_char\n",
    ")\n",
    "loss = loss_alpha + loss_char\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Varying task importance\n",
    "Character classification 2 times more important than alphabet classification\n",
    "Approach 1: Scale more important loss by a factor of 2\n",
    "loss = loss_alpha + loss_char * 2\n",
    "Approach 2: Assign weights that sum to 1\n",
    "loss = 0.33 * loss_alpha + 0.67 * loss_char\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Warning: losses on different scales\n",
    "Losses must be on the same scale before they are weighted and added\n",
    "Example tasks:\n",
    "Predict house price -> MSE loss\n",
    "Predict quality: low, medium, high -> CrossEntropy loss\n",
    "CrossEntropy is typically in the single-digits\n",
    "MSE loss can reach tens of thousands\n",
    "Model would ignore quality assessment task\n",
    "Solution: Normalize both losses before weighting and adding\n",
    "loss_price = loss_price / torch.max(loss_price)\n",
    "loss_quality = loss_quality / torch.max(loss_quality)\n",
    "loss = 0.7 * loss_price + 0.3 * loss_quality\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Let's practice!\n",
    "I N T E R M E D I AT E D E E P L E A R N I N G W I T H P Y T O R C H\n",
    "\n",
    "Wrap-up\n",
    "I N T E R M E D I AT E D E E P L E A R N I N G W I T H P Y T O R C H\n",
    "\n",
    "Michal Oleszak\n",
    "Machine Learning Engineer\n",
    "\n",
    "What you learned\n",
    "1. Training robust neural networks\n",
    "\n",
    "2. Images and convolutional neural networks\n",
    "\n",
    "PyTorch and OOP\n",
    "\n",
    "Handling images with PyTorch\n",
    "\n",
    "Optimizers\n",
    "\n",
    "Training and evaluating convolutional\n",
    "networks\n",
    "\n",
    "Vanishing and exploding gradients\n",
    "\n",
    "Data augmentation\n",
    "3. Sequences and recurrent neural networks\n",
    "\n",
    "4. Multi-input and multi-output architectures\n",
    "\n",
    "Handling sequences with PyTorch\n",
    "\n",
    "Multi-input models\n",
    "\n",
    "Training and evaluating recurrent networks\n",
    "(LSTM and GRU)\n",
    "\n",
    "Multi-output models\n",
    "Loss weighting\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "What's next?\n",
    "What you might consider learning next:\n",
    "Transformers\n",
    "Self-supervised learning\n",
    "\n",
    "Courses:\n",
    "Deep Learning for Text with PyTorch\n",
    "Deep Learning for Images with PyTorch\n",
    "Efficient AI Model Training with PyTorch\n",
    "\n",
    "INTERMEDIATE DEEP LEARNING WITH PYTORCH\n",
    "\n",
    "Congratulations and\n",
    "good luck!\n",
    "I N T E R M E D I AT E D E E P L E A R N I N G W I T H P Y T O R C H\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
