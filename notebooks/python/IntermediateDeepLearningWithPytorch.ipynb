{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "395aef8b-70bb-4c97-bd75-46c362e78350",
   "metadata": {},
   "source": [
    "# Chapter 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e457ded-a5f5-4baa-bf33-9f8ac07422ce",
   "metadata": {},
   "source": [
    "## PyTorch and object-oriented programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead0e090-e804-4f23-a058-700129fdce04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object-Oriented Programming (OOP)\n",
    "class BankAccount:\n",
    "    def __init__(self, balance):\n",
    "        self.balance = balance\n",
    "\n",
    "# __init__ is called when BankAccount object is created\n",
    "# balance is the attribute of the BankAccount object\n",
    "account = BankAccount(100)\n",
    "print(account.balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e329e1-0151-4560-a38c-39062c927d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object-Oriented Programming (OOP)\n",
    "# Methods: Python functions to perform tasks\n",
    "class BankAccount:\n",
    "    # deposit method increases balance\n",
    "    def __init__(self, balance):\n",
    "        self.balance = balance\n",
    "        \n",
    "    def deposit(self, amount):\n",
    "        self.balance += amount\n",
    "\n",
    "account = BankAccount(100)\n",
    "account.deposit(50)\n",
    "print(account.balance)\n",
    "# 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452e9fcb-e147-4079-a9b4-7999f6ce4c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cff42e1-d2a7-4cb9-8da5-b52b8546b220",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57faec22-adff-417d-8e65-addaeba318cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a0d50f-303f-49b9-a3f3-1947416d2a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c22e2bf-3693-4b0e-b831-6f9250db735a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249ca6e1-3727-4b80-9dc9-cca89d44c57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Water potability dataset\n",
    "# PyTorch Dataset\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "class WaterDataset(Dataset):\n",
    "    # init: load data, store as numpy array\n",
    "    # super().__init__() ensures\n",
    "    # WaterDataset behaves like torch Dataset\n",
    "    def __init__(self, csv_path):\n",
    "        super().__init__()\n",
    "        df = pd.read_csv(csv_path)\n",
    "        self.data = df.to_numpy()\n",
    "        \n",
    "    # len: return the size of the dataset\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "        \n",
    "    # getitem: take one argument called idx\n",
    "    # and return features and label for a single sample at index idx\n",
    "    def __getitem__(self, idx):\n",
    "        features = self.data[idx, :-1]\n",
    "        label = self.data[idx, -1]\n",
    "        return features, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3889171d-34d8-4e8c-98f7-fbb340628dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch DataLoader\n",
    "dataset_train = WaterDataset(\n",
    "    \"./data/water_potability/water_train.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fd723d-8eeb-498b-997a-87ab49d32aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    generator=torch.Generator(device=device),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e4959e-7919-4b68-be0f-16addfea738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = next(iter(dataloader_train))\n",
    "print(f\"Features: {features},\\nLabels: {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186f0043-0659-4607-bc0b-664514e76e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Model\n",
    "# Sequential model definition:\n",
    "import torch.nn as nn\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(9, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 1),\n",
    "    nn.Sigmoid(),\n",
    ")\n",
    "\n",
    "# Class-based model definition:\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(9, 16, dtype=torch.float64)\n",
    "        self.fc2 = nn.Linear(16, 8, dtype=torch.float64)\n",
    "        self.fc3 = nn.Linear(8, 1, dtype=torch.float64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = nn.functional.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d5e90c-da14-46f5-8d8e-7dea9df35675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62de50f-a2fd-4462-bdf0-2c1e1f2f565f",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(net.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78724e7-cebb-471d-9fdd-7ab921ed683a",
   "metadata": {},
   "source": [
    "## Optimizers, training, and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff47792-6c1d-4846-86dc-301ba0e85112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    for features, labels in dataloader_train:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(features)\n",
    "        loss = criterion(\n",
    "            outputs, labels.view(-1, 1)\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c07f825-7d62-4041-a30d-27089df45878",
   "metadata": {},
   "source": [
    "### Optimizers\n",
    "\n",
    "#### Stochastic Gradient Descent (SGD)\n",
    "```\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "```\n",
    "\n",
    "* Update depends on learning rate\n",
    "* Simple and efficient, for basic models\n",
    "* Rarely used in practice\n",
    "\n",
    "#### Adaptive Gradient (Adagrad)\n",
    "```\n",
    "optimizer = optim.Adagrad(net.parameters(), lr=0.01)\n",
    "```\n",
    "\n",
    "* Adapts learning rate for each parameter\n",
    "* Good for sparse data\n",
    "* May decrease the learning rate too fast\n",
    "\n",
    "#### Root Mean Square Propagation (RMSprop)\n",
    "```\n",
    "optimizer = optim.RMSprop(net.parameters(), lr=0.01)\n",
    "```\n",
    "\n",
    "* Update for each parameter based on the size of its previous gradients\n",
    "\n",
    "#### Adaptive Moment Estimation (Adam)\n",
    "```\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "```\n",
    "\n",
    "* Arguably the most versatile and widely used\n",
    "* RMSprop + gradient momentum\n",
    "* Often used as the go-to optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2a9096-90f6-44c9-aebd-05ada069e07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch DataLoader\n",
    "dataset_test = WaterDataset(\n",
    "    \"./data/water_potability/water_test.csv\"\n",
    ")\n",
    "from torch.utils.data import DataLoader\n",
    "dataloader_test = DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "generator=torch.Generator(device=device),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea551a1-3d28-4830-a620-aeb8448633b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "# Set up accuracy metric\n",
    "\n",
    "# Put model in eval mode and iterate over\n",
    "# test data batches with no gradients\n",
    "\n",
    "# Pass data to model to get predicted\n",
    "# probabilities\n",
    "# Compute predicted labels\n",
    "# Update accuracy metric\n",
    "\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "acc = Accuracy(task=\"binary\")\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for features, labels in dataloader_test:\n",
    "        outputs = net(features)\n",
    "        preds = (outputs >= 0.5).float()\n",
    "        acc(preds, labels.view(-1, 1))\n",
    "\n",
    "accuracy = acc.compute()\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed097ea2-2ac6-44b3-b2db-5086ed0dc88e",
   "metadata": {},
   "source": [
    "## Vanishing and exploding gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358cc378-6e9e-434a-8747-0b2f251c349f",
   "metadata": {},
   "source": [
    "Vanishing gradients\n",
    "* Gradients get smaller and smaller during backward pass\n",
    "* Earlier layers get small parameter updates\n",
    "* Model doesn't learn\n",
    "\n",
    "Exploding gradients\n",
    "* Gradients get bigger and bigger\n",
    "* Parameter updates are too large\n",
    "* Training diverges\n",
    "\n",
    "Solution to unstable gradients\n",
    "1. Proper weights initialization\n",
    "2. Good activations\n",
    "3. Batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d721b6f-53b4-4298-95a7-f42b9a29a121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights initialization\n",
    "layer = nn.Linear(8, 1)\n",
    "print(layer.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545cf329-e914-4151-a2cc-3795a0991ba1",
   "metadata": {},
   "source": [
    "Weights initialization\n",
    "Good initialization ensures:\n",
    "* Variance of layer inputs = variance of layer outputs\n",
    "* Variance of gradients the same before and after a layer\n",
    "\n",
    "How to achieve this depends on the activation:\n",
    "For ReLU and similar, we can use He/Kaiming initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb5e149-a270-437a-ad04-75b45aa1fdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights initialization\n",
    "import torch.nn.init as init\n",
    "init.kaiming_uniform_(layer.weight)\n",
    "print(layer.weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ee12c0-fa7d-4b15-be3f-fadc92e45e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# He / Kaiming initialization\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(9, 16)\n",
    "        self.fc2 = nn.Linear(16, 8)\n",
    "        self.fc3 = nn.Linear(8, 1)\n",
    "        \n",
    "        init.kaiming_uniform_(self.fc1.weight)\n",
    "        init.kaiming_uniform_(self.fc2.weight)\n",
    "        init.kaiming_uniform_(\n",
    "            self.fc3.weight,\n",
    "            nonlinearity=\"sigmoid\",\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = nn.functional.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc86f54-4c48-4d30-82d4-4e5cda9d282d",
   "metadata": {},
   "source": [
    "Activation functions\n",
    "* Often used as the default activation\n",
    "* `nn.functional.elu()`\n",
    "* `nn.functional.relu()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30017f10-97d5-4f68-847d-bc0dadab75b4",
   "metadata": {},
   "source": [
    "#### Batch normalization\n",
    "After a layer:\n",
    "1. Normalize the layer's outputs by:\n",
    "   * Subtracting the mean\n",
    "   * Dividing by the standard deviation\n",
    "2. Scale and shift normalized outputs using learned parameters\n",
    "   * Model learns optimal inputs distribution for each layer:\n",
    "   * Faster loss decrease\n",
    "   * Helps against unstable gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bfc2f8-6111-4b37-983d-dbec35e25601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch normalization\n",
    "# Simple one layer example\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(9, 16)\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = nn.functional.elu(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f963dd-3c18-4570-b6dc-53a1441895e1",
   "metadata": {},
   "source": [
    "# Chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472c319d-f1dd-4c5f-8530-9203adbf5cd1",
   "metadata": {},
   "source": [
    "## Handling images with PyTorch\n",
    "\n",
    "[Clouds dataset](https://www.kaggle.com/competitions/cloud-type-classification2/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b30bd59-8547-4e4d-8857-96b0ffcd5509",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loading images to PyTorch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((128, 128)),\n",
    "])\n",
    "dataset_train = ImageFolder(\n",
    "    \"data/clouds_train\",\n",
    "    transform=train_transforms,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29623fd2-a38d-426d-820b-353c1bf3af39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying images\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    shuffle=True,\n",
    "    batch_size=1,\n",
    ")\n",
    "image, label = next(iter(dataloader_train))\n",
    "print(image.shape)\n",
    "\n",
    "# torch.Size([1, 3, 128, 128])\n",
    "\n",
    "image = image.squeeze().permute(1, 2, 0)\n",
    "print(image.shape)\n",
    "\n",
    "# torch.Size([128, 128, 3])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2f18f8-c8ba-4f5b-99f5-b19949eafdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((128, 128)),\n",
    "])\n",
    "dataset_train = ImageFolder(\n",
    "    \"data/clouds/train\",\n",
    "    transform=train_transforms,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aebd61f-a5b8-4dc0-975f-e2254d719265",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07960fcc-bc77-4625-9a87-32402c4ae002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-padding\n",
    "# Add a frames of zeros to convolutional layer's input\n",
    "# nn.Conv2d(\n",
    "#     3, 32, kernel_size=3, padding=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7e153f-cfc1-48b0-a89f-4c26695bb584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max Pooling\n",
    "# Slide non-overlapping window over input\n",
    "# At each position, retain only the maximum value\n",
    "# Used after convolutional layers to reduce spatial dimensions\n",
    "# nn.MaxPool2d(kernel_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53148318-0733-4749-8de6-12d301185f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Convolutional Neural Network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.classifier = nn.Linear(64*16*16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a1025a-a172-4caa-894f-8744d40f1a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extractor output size\n",
    "self.feature_extractor = nn.Sequential(\n",
    "    nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "    nn.ELU(),\n",
    "    nn.MaxPool2d(kernel_size=2),\n",
    "    nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "    nn.ELU(),\n",
    "    nn.MaxPool2d(kernel_size=2),\n",
    "    nn.Flatten(),\n",
    ")\n",
    "self.classifier = nn.Linear(64*16*16, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c4eca6-1abe-47b8-b977-e474a019ba77",
   "metadata": {},
   "source": [
    "## Training image classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f5fc48-5f1b-4816-aa67-286271fe80e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentations for cloud classification\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.RandomAutocontrast(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((128, 128))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b27d52-96ae-4b11-9b7a-f81376dab0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image classifier training loop\n",
    "net = Net(num_classes=7)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for images, labels in dataloader_train:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f31578c-d078-4c4a-9bb6-054bc3b0fa53",
   "metadata": {},
   "source": [
    "## Evaluating image classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09215f4c-24fa-4a0c-8619-7778c369ab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation at test time\n",
    "\n",
    "# Data augmentation for training data:\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.RandomAutocontrast(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((64, 64)),\n",
    "])\n",
    "\n",
    "dataset_train = ImageFolder(\n",
    "    \"clouds_train\",\n",
    "    transform=train_transforms,\n",
    ")\n",
    "\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    #\n",
    "    # NO DATA AUGMENTATION AT TEST TIME\n",
    "    #\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((64, 64)),\n",
    "])\n",
    "\n",
    "dataset_test = ImageFolder(\n",
    "    \"clouds_test\",\n",
    "    transform=test_transforms,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821639d0-d8b7-46de-9a7e-6082c976451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging multi-class metrics\n",
    "from torchmetrics import Recall\n",
    "recall_per_class = Recall(task=\"multiclass\", num_classes=7, average=None)\n",
    "recall_micro = Recall(task=\"multiclass\", num_classes=7, average=\"micro\")\n",
    "recall_macro = Recall(task=\"multiclass\", num_classes=7, average=\"macro\")\n",
    "recall_weighted = Recall(task=\"multiclass\", num_classes=7, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86ddb66-f595-447d-beec-3b92ca540ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation loop\n",
    "from torchmetrics import Precision, Recall\n",
    "\n",
    "metric_precision = Precision(\n",
    "    task=\"multiclass\", num_classes=7, average=\"macro\"\n",
    ")\n",
    "\n",
    "metric_recall = Recall(\n",
    "    task=\"multiclass\", num_classes=7, average=\"macro\"\n",
    ")\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloader_test:\n",
    "        outputs = net(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        metric_precision(preds, labels)\n",
    "        metric_recall(preds, labels)\n",
    "precision = metric_precision.compute()\n",
    "recall = metric_recall.compute()\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540151da-ddd5-428e-83c9-3e6d0505c012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing performance per class\n",
    "metric_recall = Recall(\n",
    "    task=\"multiclass\", num_classes=7, average=None\n",
    ")\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloader_test:\n",
    "        outputs = net(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        metric_recall(preds, labels)\n",
    "recall = metric_recall.compute()\n",
    "\n",
    "print(recall)\n",
    "\n",
    "dataset_test.class_to_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779af461-979a-469a-a409-10ea53993dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing performance per class\n",
    "# k = class name, e.g. cirriform clouds\n",
    "{\n",
    "    k: recall[v].item()\n",
    "    for k, v\n",
    "    in dataset_test.class_to_idx.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2406c8d9-58b6-4f37-a5c9-b762e4a8584d",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d542a41b-0497-4ffb-9688-6624352b15e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics\n",
    "metric_precision = Precision(task=\"multiclass\", num_classes=7, average=\"macro\")\n",
    "metric_recall = Recall(task=\"multiclass\", num_classes=7, average=\"macro\")\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloader_test:\n",
    "        outputs = net(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        metric_precision(preds, labels)\n",
    "        metric_recall(preds, labels)\n",
    "\n",
    "precision = metric_precision.compute()\n",
    "recall = metric_recall.compute()\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b548bab1-f191-483b-bb55-26e00eadb3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define precision metric\n",
    "metric_precision = Precision(\n",
    "    task=\"multiclass\", num_classes=7, average=None\n",
    ")\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloader_test:\n",
    "        outputs = net(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        metric_precision(preds, labels)\n",
    "precision = metric_precision.compute()\n",
    "\n",
    "# Get precision per class\n",
    "precision_per_class = {\n",
    "    k: precision[v].item()\n",
    "    for k, v \n",
    "    in dataset_test.class_to_idx.items()\n",
    "}\n",
    "print(precision_per_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65262e8-fbb3-476f-90d3-4b7e2f18c0ae",
   "metadata": {},
   "source": [
    "# Chapter 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cd61df-5f43-493c-926f-015942c5c434",
   "metadata": {},
   "source": [
    "## Handling sequences with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcfb33bc-2ab0-4c60-8770-73ba47f383fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "507dccf9-2c56-499c-9f3b-01907262bbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv(\"./data/electricity_consump/electricity_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe5e9a87-9a21-4788-9a17-b684170d462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Trindade,Artur. (2015). ElectricityLoadDiagrams20112014. UCI Machine Learning Repository.\n",
    "# https://doi.org/10.24432/C58C86.\n",
    "\n",
    "# Creating sequences in Python\n",
    "import numpy as np\n",
    "def create_sequences(df, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(df) - seq_length):\n",
    "        x = df.iloc[i:(i+seq_length), 1]\n",
    "        y = df.iloc[i+seq_length, 1]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1770396-b55d-4ba0-ae6f-39a5aa1faf1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 00:15:00</td>\n",
       "      <td>-0.704319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 00:30:00</td>\n",
       "      <td>-0.704319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 00:45:00</td>\n",
       "      <td>-0.678983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>-0.653647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 01:15:00</td>\n",
       "      <td>-0.704319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105210</th>\n",
       "      <td>2013-12-31 22:45:00</td>\n",
       "      <td>-0.932595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105211</th>\n",
       "      <td>2013-12-31 23:00:00</td>\n",
       "      <td>-0.907259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105212</th>\n",
       "      <td>2013-12-31 23:15:00</td>\n",
       "      <td>-0.932595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105213</th>\n",
       "      <td>2013-12-31 23:30:00</td>\n",
       "      <td>-0.932595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105214</th>\n",
       "      <td>2013-12-31 23:45:00</td>\n",
       "      <td>-0.932595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105215 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp  consumption\n",
       "0       2011-01-01 00:15:00    -0.704319\n",
       "1       2011-01-01 00:30:00    -0.704319\n",
       "2       2011-01-01 00:45:00    -0.678983\n",
       "3       2011-01-01 01:00:00    -0.653647\n",
       "4       2011-01-01 01:15:00    -0.704319\n",
       "...                     ...          ...\n",
       "105210  2013-12-31 22:45:00    -0.932595\n",
       "105211  2013-12-31 23:00:00    -0.907259\n",
       "105212  2013-12-31 23:15:00    -0.932595\n",
       "105213  2013-12-31 23:30:00    -0.932595\n",
       "105214  2013-12-31 23:45:00    -0.932595\n",
       "\n",
       "[105215 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78959242-b0fe-4035-9e5f-9f33f08e4140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105119, 96) (105119,)\n"
     ]
    }
   ],
   "source": [
    "# TensorDataset\n",
    "# Create training examples\n",
    "seq_length = 96\n",
    "X_train, y_train = create_sequences(train_data, seq_length)\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "# (34944, 96) (34944,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "917c278e-6959-41dc-9aa4-be5b0641d4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert them to a Torch Dataset\n",
    "from torch.utils.data import TensorDataset\n",
    "dataset_train = TensorDataset(\n",
    "    torch.from_numpy(X_train).float(),\n",
    "    torch.from_numpy(y_train).float(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21b0743-37fb-4fba-969c-be2cf9c380d4",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7e6e7f-176f-4295-ba40-9dc60dd9f37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN in PyTorch\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=1,\n",
    "            hidden_size=32,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc = nn.Linear(32, 1)\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(2, x.size(0), 32)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd08d558-029f-4038-8f3c-0c530c4e12a2",
   "metadata": {},
   "source": [
    "## LSTM and GRU cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57b76336-7176-493d-818e-3ddaca2f95b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "939fd3a2-8d7b-4e61-97b8-52e6df5cd344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM in PyTorch\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=1,\n",
    "            hidden_size=32,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(2, x.size(0), 32)\n",
    "        c0 = torch.zeros(2, x.size(0), 32)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a89da1df-88cc-4cb3-8afd-1197a8d69512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU in PyTorch\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=1,\n",
    "            hidden_size=32,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(2, x.size(0), 32)\n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37092ec-8abd-4686-990a-9afad3b167c0",
   "metadata": {},
   "source": [
    "## Training and evaluating RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9dd374f5-2980-42fe-afc9-a365d1d81abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE (JS): Is this the way to go for time series data\n",
    "from torch.utils.data import DataLoader\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    # generator=torch.Generator(device=device),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09d56d71-2754-4a42-9f46-03abb5cb9481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for seqs, labels in dataloader_train:\n",
    "    # seqs = seqs.view(32, 96, 1)\n",
    "    print(seqs.shape == torch.Size([32, 96]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70588ccd-4e0a-4f7a-adf9-c0802af1b752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "net = Net()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(\n",
    "    net.parameters(), lr=0.001\n",
    ")\n",
    "\n",
    "num_epochs=3\n",
    "for epoch in range(num_epochs):\n",
    "    for seqs, labels in dataloader_train:\n",
    "        if (seqs.shape != torch.Size([32, 96])):\n",
    "            continue # The last entry might not have 32 records\n",
    "        seqs = seqs.view(32, 96, 1)\n",
    "        outputs = net(seqs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b90bba7-ebb7-41aa-9145-73dfbaf716b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation loop\n",
    "mse = torchmetrics.MeanSquaredError()\n",
    "\n",
    "# Set up MSE metric\n",
    "# Iterate through test data with no gradients\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for seqs, labels in test_loader:\n",
    "        # Reshape model inputs\n",
    "        # Squeeze model outputs\n",
    "        seqs = seqs.view(32, 96, 1)\n",
    "        # Update the metric\n",
    "        outputs = net(seqs).squeeze()\n",
    "        # Compute final metric value\n",
    "        mse(outputs, labels)\n",
    "print(f\"Test MSE: {mse.compute()}\")\n",
    "\n",
    "# Test MSE: 0.13292162120342255\n",
    "\n",
    "# LSTM vs. GRU\n",
    "# LSTM:\n",
    "# Test MSE: 0.13292162120342255\n",
    "\n",
    "# GRU:\n",
    "# Test MSE: 0.12187089771032333\n",
    "\n",
    "# GRU preferred: same or better results with less processing power"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5917894a-0dc8-4d69-a280-d730a97265f5",
   "metadata": {},
   "source": [
    "# Chapter 4: Multi-Input & Multi-Output Architectures\n",
    "Omniglot dataset  \n",
    "Lake, B. M., Salakhutdinov, R., and Tenenbaum, J. B. (2015). Human-level concept learning through probabilistic program induction. Science, 350(6266), 1332-1338."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117bf133-4b67-4f23-a407-7340dac33a04",
   "metadata": {},
   "source": [
    "## Multi-input models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f558bb5-5101-41be-9c33-4ad4ce2d7035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two-input Dataset\n",
    "from PIL import Image\n",
    "\n",
    "# Assign samples and transforms\n",
    "class OmniglotDataset(Dataset):\n",
    "    def __init__(self, transform, samples):\n",
    "        self.transform = transform\n",
    "        self.samples = samples\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, alphabet, label = self.samples[idx]\n",
    "        img = Image.open(img_path).convert('L')\n",
    "        img = self.transform(img)\n",
    "        return img, alphabet, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5cd8e7-7da0-4b12-8ee3-5bddbca17624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor concatenation\n",
    "x = torch.tensor([\n",
    "    [1, 2, 3],\n",
    "])\n",
    "y = torch.tensor([\n",
    "    [4, 5, 6],\n",
    "])\n",
    "\n",
    "# Concatenation along axis 0\n",
    "torch.cat((x, y), dim=0)\n",
    "# [[1, 2, 3],\n",
    "# [4, 5, 6]]\n",
    "\n",
    "# Concatenation along axis 1\n",
    "torch.cat((x, y), dim=1)\n",
    "# [[1, 2, 3, 4, 5, 6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0055076c-b87e-4839-a75b-b47c97471e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two-input architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.image_layer = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ELU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16*32*32, 128)\n",
    "        )\n",
    "        self.alphabet_layer = nn.Sequential(\n",
    "            nn.Linear(30, 8),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128 + 8, 964),\n",
    "        )\n",
    "\n",
    "    # Two-input architecture\n",
    "    def forward(self, x_image, x_alphabet):\n",
    "        x_image = self.image_layer(x_image)\n",
    "        x_alphabet = self.alphabet_layer(x_alphabet)\n",
    "        x = torch.cat((x_image, x_alphabet), dim=1)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433f9e69-7543-4d5e-ad2c-570027a1a4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "for epoch in range(10):\n",
    "    for img, alpha, labels in dataloader_train:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(img, alpha)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Training data consists of three items:\n",
    "# Image\n",
    "# Alphabet vector\n",
    "# Labels\n",
    "# We pass the model images and alphabets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced83fe2-daf1-40fb-b7fc-f7dbb2839c42",
   "metadata": {},
   "source": [
    "## Multi-output models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e49834a-9f2f-4efa-a54b-356e40afb3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Two-output Dataset\n",
    "class OmniglotDataset(Dataset):\n",
    "def __init__(self, transform, samples):\n",
    "self.transform = transform\n",
    "self.samples = samples\n",
    "\n",
    "We can use the same Dataset...\n",
    "...with updated samples:\n",
    "print(samples[0])\n",
    "\n",
    "def __len__(self):\n",
    "return len(self.samples)\n",
    "\n",
    "[(\n",
    "'omniglot_train/.../0459_14.png',\n",
    "\n",
    "def __getitem__(self, idx):\n",
    "img_path, alphabet, label = \\\n",
    "self.samples[idx]\n",
    "\n",
    "0,\n",
    "0,\n",
    ")]\n",
    "\n",
    "img = Image.open(img_path).convert('L')\n",
    "img = self.transform(img)\n",
    "return img, alphabet, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9e03b1-37ce-484e-a257-b9ae080fb097",
   "metadata": {},
   "outputs": [],
   "source": [
    "Two-output architecture\n",
    "class Net(nn.Module):\n",
    "def __init__(self, num_alpha, num_char):\n",
    "super().__init__()\n",
    "self.image_layer = nn.Sequential(\n",
    "nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "nn.MaxPool2d(kernel_size=2),\n",
    "nn.ELU(),\n",
    "nn.Flatten(),\n",
    "nn.Linear(16*32*32, 128)\n",
    "\n",
    "Define image-processing sub-network\n",
    "Define output-specific classifiers\n",
    "Pass image through dedicated sub-network\n",
    "Pass the result through each output layer\n",
    "Return both outputs\n",
    "\n",
    ")\n",
    "self.classifier_alpha = nn.Linear(128, 30)\n",
    "self.classifier_char = nn.Linear(128, 964)\n",
    "def forward(self, x):\n",
    "x_image = self.image_layer(x)\n",
    "output_alpha = self.classifier_alpha(x_image)\n",
    "output_char = self.classifier_char(x_image)\n",
    "return output_alpha, output_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960e64a2-d773-4409-8b25-06fecaeb39eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Training loop\n",
    "for epoch in range(10):\n",
    "for images, labels_alpha, labels_char \\\n",
    "in dataloader_train:\n",
    "optimizer.zero_grad()\n",
    "outputs_alpha, outputs_char = net(images)\n",
    "loss_alpha = criterion(\n",
    "\n",
    "Model produces two outputs\n",
    "Calculate loss for each output\n",
    "Combine the losses to one total loss\n",
    "Backprop and optimize with the total loss\n",
    "\n",
    "outputs_alpha, labels_alpha\n",
    ")\n",
    "loss_char = criterion(\n",
    "outputs_char, labels_char\n",
    ")\n",
    "loss = loss_alpha + loss_char\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40799e7-0e72-4bab-bb31-757a255ec7b9",
   "metadata": {},
   "source": [
    "## Evaluation of multioutput models and loss weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b8c5f4-1ae6-4d1e-8ba0-5be16a06f3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model evaluation\n",
    "acc_alpha = Accuracy(\n",
    "task=\"multiclass\", num_classes=30\n",
    ")\n",
    "acc_char = Accuracy(\n",
    "task=\"multiclass\", num_classes=964\n",
    ")\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "for images, labels_alpha, labels_char \\\n",
    "in dataloader_test:\n",
    "\n",
    "Set up metric for each output\n",
    "Iterate over test loader and get outputs\n",
    "Calculate prediction for each output\n",
    "Update accuracy metrics\n",
    "Calculate final accuracy scores\n",
    "print(f\"Alphabet: {acc_alpha.compute()}\")\n",
    "print(f\"Character: {acc_char.compute()}\")\n",
    "\n",
    "out_alpha, out_char = net(images)\n",
    "_, pred_alpha = torch.max(out_alpha, 1)\n",
    "\n",
    "Alphabet: 0.3166305720806122\n",
    "\n",
    "_, pred_char = torch.max(out_char, 1)\n",
    "\n",
    "Character: 0.24064336717128754\n",
    "\n",
    "acc_alpha(pred_alpha, labels_alpha)\n",
    "acc_char(pred_char, labels_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883fb908-13e2-45e6-82dd-8e461c63f443",
   "metadata": {},
   "outputs": [],
   "source": [
    "Multi-output training loop revisited\n",
    "for epoch in range(10):\n",
    "for images, labels_alpha, labels_char \\\n",
    "in dataloader_train:\n",
    "\n",
    "Two losses: for alphabets and characters\n",
    "Final loss defined as sum of alphabet and\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "character losses:\n",
    "\n",
    "outputs_alpha, outputs_char = net(images)\n",
    "\n",
    "loss = loss_alpha + loss_char\n",
    "\n",
    "loss_alpha = criterion(\n",
    "outputs_alpha, labels_alpha\n",
    ")\n",
    "\n",
    "Both classification tasks deemed equally\n",
    "important\n",
    "\n",
    "loss_char = criterion(\n",
    "outputs_char, labels_char\n",
    ")\n",
    "loss = loss_alpha + loss_char\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baf7e48-6eb8-4a62-8375-06de742a7773",
   "metadata": {},
   "outputs": [],
   "source": [
    "Varying task importance\n",
    "Character classification 2 times more important than alphabet classification\n",
    "Approach 1: Scale more important loss by a factor of 2\n",
    "loss = loss_alpha + loss_char * 2\n",
    "Approach 2: Assign weights that sum to 1\n",
    "loss = 0.33 * loss_alpha + 0.67 * loss_char\n",
    "\n",
    "Warning: losses on different scales\n",
    "Losses must be on the same scale before they are weighted and added\n",
    "Example tasks:\n",
    "Predict house price -> MSE loss\n",
    "Predict quality: low, medium, high -> CrossEntropy loss\n",
    "CrossEntropy is typically in the single-digits\n",
    "MSE loss can reach tens of thousands\n",
    "Model would ignore quality assessment task\n",
    "Solution: Normalize both losses before weighting and adding\n",
    "loss_price = loss_price / torch.max(loss_price)\n",
    "loss_quality = loss_quality / torch.max(loss_quality)\n",
    "loss = 0.7 * loss_price + 0.3 * loss_quality\n",
    "\n",
    "What you learned\n",
    "1. Training robust neural networks\n",
    "2. Images and convolutional neural networks\n",
    "\n",
    "PyTorch and OOP\n",
    "Handling images with PyTorch\n",
    "Optimizers\n",
    "Training and evaluating convolutional networks\n",
    "Vanishing and exploding gradients\n",
    "\n",
    "Data augmentation\n",
    "3. Sequences and recurrent neural networks\n",
    "4. Multi-input and multi-output architectures\n",
    "\n",
    "Handling sequences with PyTorch\n",
    "\n",
    "Multi-input models\n",
    "\n",
    "Training and evaluating recurrent networks\n",
    "(LSTM and GRU)\n",
    "\n",
    "Multi-output models\n",
    "Loss weighting\n",
    "\n",
    "What's next?\n",
    "What you might consider learning next:\n",
    "Transformers\n",
    "Self-supervised learning\n",
    "\n",
    "Courses:\n",
    "Deep Learning for Text with PyTorch\n",
    "Deep Learning for Images with PyTorch\n",
    "Efficient AI Model Training with PyTorch\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
