{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed677bd8-2127-4ed7-8ae8-218e44918ccb",
   "metadata": {},
   "source": [
    "# Chapter 1: Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea78490-34ac-461f-b229-fe1c6bf946bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring model performance\n",
    "# Using Iris dataset rather than what's used in the videos\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris(as_frame=True)\n",
    "X = iris.data # [[\"sepal length (cm)\", \"sepal width (cm)\"]]\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c525d90-7dd2-4fd9-9f70-e4cc1b1d245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddceace-d154-4524-93dd-5cb60b45234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html\n",
    "from sklearn.cluster import KMeans\n",
    "model = KMeans(n_clusters=3)\n",
    "model.fit(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2df7354-4348-4241-afbc-9fccaeacf111",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = model.predict(samples)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283a8ea3-9cb6-43c0-84b0-6a9e6d59d2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels = model.predict(new_samples)\n",
    "print(new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804e0f33-bc6a-41cf-b50c-eb3746083ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots\n",
    "import matplotlib.pyplot as plt\n",
    "xs = samples[:,0]\n",
    "ys = samples[:,2]\n",
    "plt.scatter(xs, ys, c=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5878c4e0-2fcf-4fcf-8c2a-a65ec789c03a",
   "metadata": {},
   "source": [
    "## Evaluating a clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ba05fb-1fb8-4d06-828c-8e49903dfbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aligning labels and species\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'labels': labels, 'species': species})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dbb027-f5a2-49c9-869c-a7fd01deb398",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crosstab of labels and species\n",
    "ct = pd.crosstab(df['labels'], df['species'])\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1ad03f-1189-430a-bdac-0ac05eb4f04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "model = KMeans(n_clusters=3)\n",
    "model.fit(samples)\n",
    "print(model.inertia_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21519efb-659f-440f-94c6-1b01b58d1faa",
   "metadata": {},
   "source": [
    "## Transforming features for better clusterings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5923c8a7-9523-4e72-8206-c1a001cac7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clustering the wines\n",
    "from sklearn.cluster import KMeans\n",
    "model = KMeans(n_clusters=3)\n",
    "labels = model.fit_predict(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c89d8c1-1b55-4935-9a6d-d1bb280ed32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clusters vs. varieties\n",
    "df = pd.DataFrame({'labels': labels, 'varieties': varieties})\n",
    "ct = pd.crosstab(df['labels'], df['varieties'])\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c07de90-90b8-4320-a0bf-b5d399f156ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(samples)\n",
    "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "samples_scaled = scaler.transform(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c87a01c-6de7-4ebc-8832-302113732ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipelines combine multiple steps\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "scaler = StandardScaler()\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipeline = make_pipeline(scaler, kmeans)\n",
    "pipeline.fit(samples)\n",
    "\n",
    "labels = pipeline.predict(samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52c1da4-4287-4441-803b-134544acca5b",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fa7e2d-7f52-4822-a9d1-15e8247eb8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Normalizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# Create a normalizer: normalizer\n",
    "normalizer = Normalizer()\n",
    "\n",
    "# Create a KMeans model with 10 clusters: kmeans\n",
    "kmeans = KMeans(n_clusters=10)\n",
    "\n",
    "# Make a pipeline chaining normalizer and kmeans: pipeline\n",
    "pipeline = make_pipeline(normalizer, kmeans)\n",
    "# Fit pipeline to the daily price movements\n",
    "pipeline.fit(movements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584e09c3-a1c5-4662-8ea6-4570c012186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Predict the cluster labels: labels\n",
    "labels = pipeline.predict(movements)\n",
    "\n",
    "# Create a DataFrame aligning labels and companies: df\n",
    "df = pd.DataFrame({'labels': labels, 'companies': companies})\n",
    "\n",
    "# Display df sorted by cluster label\n",
    "print(df.sort_values(['labels']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b27c0f2-c4ef-4af8-aac1-96e33ef7185b",
   "metadata": {},
   "source": [
    "# Chapter 2: Visualizing hierarchies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1392e0b0-9aa0-4d79-9fdb-7839c7758a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hierarchical clustering with SciPy\n",
    "#Given samples (the array of scores), and country_names\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "mergings = linkage(samples, method='complete')\n",
    "dendrogram(mergings,\n",
    "labels=country_names,\n",
    "leaf_rotation=90,\n",
    "leaf_font_size=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d5807f-c9de-4487-9eaa-2cce75d04c82",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d2bb03-c369-4fdc-bb5b-3d5b3d6ac50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import normalize\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Normalize the movements: normalized_movements\n",
    "normalized_movements = normalize(movements)\n",
    "\n",
    "# Calculate the linkage: mergings\n",
    "mergings = linkage(normalized_movements, method='complete')\n",
    "\n",
    "# Plot the dendrogram\n",
    "dendrogram(mergings, labels=companies, leaf_rotation=90, leaf_font_size=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a5d174-921a-45a4-941b-e269de0befb7",
   "metadata": {},
   "source": [
    "## Cluster labels in hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c7c026-d04c-4c68-9cf7-54f390c1993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting cluster labels using fcluster\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "mergings = linkage(samples, method='complete')\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    " = fcluster(mergings, 15, criterion='distance')\n",
    "print(labels)\n",
    "\n",
    "#Aligning cluster labels with country names\n",
    "# Given a list of strings country_names :\n",
    "import pandas as pd\n",
    "pairs = pd.DataFrame({'labels': labels, 'countries': country_names})\n",
    "print(pairs.sort_values('labels'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20385d0-ef28-48fd-8e71-84e35a4aef3b",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22af0ed-0ff4-449f-b46e-9e2fb77c22d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This doesn't seem to have the same number of rows as\n",
    "#       the samples data in the environment\n",
    "# Load grains data\n",
    "import pandas as pd\n",
    "data = pd.read_csv('data/Grains/seeds.csv', header=None)\n",
    "data = data.sample(16, replace=False)\n",
    "samples=data.values[:, 0:7]\n",
    "grain_ids = data.values[:, 7]\n",
    "data\n",
    "# pd.read_csv('data/Grains/seeds-width-vs-length.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96530ec-8281-4779-a0dd-28462ffcb9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the necessary imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "# Calculate the linkage: mergings\n",
    "mergings = linkage(samples, method='single')\n",
    "\n",
    "# Plot the dendrogram\n",
    "dendrogram(mergings, labels=np.arange(0, samples.shape[0]), leaf_rotation=90, leaf_font_size=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e299c81-3bc9-4771-806e-e2fc97ceddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the necessary imports\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "\n",
    "# Use fcluster to extract labels: labels\n",
    "labels = fcluster(mergings, 1.5, criterion='distance')\n",
    "\n",
    "# Create a DataFrame with labels and varieties as columns: df\n",
    "df = pd.DataFrame({'labels': labels, 'varieties': grain_ids})\n",
    "\n",
    "# Create crosstab: ct\n",
    "ct = pd.crosstab(df['labels'], df['varieties'])\n",
    "\n",
    "# Display ct\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c64acdd-2270-4eb1-b25e-5b355370d6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mergings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e808518-8758-4694-8667-e8f8ff10ff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(\n",
    "    samples[\n",
    "        mergings[0,0].astype(int),\n",
    "        :\n",
    "    ] - samples[\n",
    "        mergings[0, 1].astype(int),\n",
    "        :\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78f723e-1451-4b53-828f-cbc2a7bd91b0",
   "metadata": {},
   "source": [
    "## t-SNE for 2-dimensional maps\n",
    "t-distributed stochastic neighbor embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7b30dc-cb79-4222-8e29-008107b82f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring model performance\n",
    "# Using Iris dataset rather than what's used in the videos\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris(as_frame=True)\n",
    "X = iris.data # [[\"sepal length (cm)\", \"sepal width (cm)\"]]\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b085964-20d4-4ded-8690-1b82c5b30c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = X.values\n",
    "species = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ac9389-6daa-462c-9a24-285748896503",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t-SNE in sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "model = TSNE(learning_rate=100)\n",
    "transformed = model.fit_transform(samples)\n",
    "xs = transformed[:,0]\n",
    "ys = transformed[:,1]\n",
    "plt.scatter(xs, ys, c=species)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d31faf-0b46-4a48-bc9e-97efb2608d55",
   "metadata": {},
   "source": [
    "## Chapter 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d777131e-7d76-4c1f-b0e0-620b23482d21",
   "metadata": {},
   "source": [
    "## Visualizing the PCA transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41b1851-087b-4e70-9dd9-69882e191ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring model performance\n",
    "# Using Wine dataset \n",
    "from sklearn.datasets import load_wine\n",
    "wine = load_wine(as_frame=True)\n",
    "X = wine.data.rename(\n",
    "    columns = {\n",
    "        \"od280/od315_of_diluted_wines\": \"od280\"\n",
    "    }\n",
    ")\n",
    "y = wine.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18947147-074a-43f6-b6d9-b4ce6979200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = X[[\"total_phenols\", \"od280\"]]\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5958f7f2-761d-410a-b190-28c0a8b24aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "model = PCA()\n",
    "model.fit(samples)\n",
    "transformed = model.transform(samples)\n",
    "\n",
    "print(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69523932-1259-4b8d-a429-6ca8a5c477ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95f73eb-e7e7-4c46-a09e-767a81a55bfd",
   "metadata": {},
   "source": [
    "## Intrinsic dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e4262a-7130-4ff3-8211-d02daa607088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iris dataset\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris(as_frame=True)\n",
    "X = iris.data \n",
    "features = [\"sepal length (cm)\", \"sepal width (cm)\", \"petal width (cm)\"]\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d94312-e4e9-4860-a57c-7aba0f20da92",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = X[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d5fe13-bddc-40bd-9999-ddbfd9e35e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the variances of PCA features\n",
    "# samples = array of versicolor samples\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca.fit(samples)\n",
    "PCA()\n",
    "features = range(pca.n_components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b7ee1f-e579-4064-baac-9052d1b6b7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the variances of PCA features\n",
    "plt.bar(features, pca.explained_variance_)\n",
    "plt.xticks(features)\n",
    "plt.ylabel('variance')\n",
    "plt.xlabel('PCA feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17372f9f-018d-44f4-9d76-eb4f56bf9b66",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a9c330-b93e-4c32-90aa-759155d6d738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following was run with a fish data set\n",
    "\n",
    "# Perform the necessary imports\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create scaler: scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create a PCA instance: pca\n",
    "pca = PCA()\n",
    "\n",
    "# Create pipeline: pipeline\n",
    "pipeline = make_pipeline(scaler, pca)\n",
    "\n",
    "# Fit the pipeline to 'samples'\n",
    "pipeline.fit(samples)\n",
    "\n",
    "# Plot the explained variances\n",
    "features = range(pca.n_components_)\n",
    "plt.bar(features, pca.explained_variance_)\n",
    "plt.xlabel('PCA feature')\n",
    "plt.ylabel('variance')\n",
    "plt.xticks(features)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85286632-a63b-42d2-b268-a3333a2a27cd",
   "metadata": {},
   "source": [
    "## Dimension reduction with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949dbb65-318b-4294-bb21-23b020f56843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all features of Iris dataset\n",
    "iris = load_iris(as_frame=True)\n",
    "X = iris.data \n",
    "y = iris.target\n",
    "samples = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbc2ca6-43c0-479d-bbeb-eb9b10a3632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension reduction of iris dataset\n",
    "# samples = array of iris measurements (4 features)\n",
    "# species = list of iris species numbers\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(samples)\n",
    "\n",
    "transformed = pca.transform(samples)\n",
    "print(transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31395b2a-2854-4b13-8d0d-9e9e02ac3a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "xs = transformed[:,0]\n",
    "ys = transformed[:,1]\n",
    "plt.scatter(xs, ys, c=species)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d7eb57-4f81-4e7a-9476-765edf162992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE (JS): No example data for this cell\n",
    "\n",
    "# TruncatedSVD and csr_matrix\n",
    "# scikit-learn PCA doesn't support csr_matrix\n",
    "# Use scikit-learn TruncatedSVD instead\n",
    "# Performs same transformation\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "model = TruncatedSVD(n_components=3)\n",
    "model.fit(documents)\n",
    "\n",
    "# documents is csr_matrix\n",
    "transformed = model.transform(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f9a0a2-9297-44e7-ad2c-ac2d4d126585",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd739837-05d6-445a-813f-105bd95b8964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create a TfidfVectorizer: tfidf\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# Apply fit_transform to document: csr_mat\n",
    "csr_mat = tfidf.fit_transform(documents)\n",
    "\n",
    "# Print result of toarray() method\n",
    "print(csr_mat.toarray())\n",
    "\n",
    "# Get the words: words\n",
    "words = tfidf.get_feature_names()\n",
    "\n",
    "# Print words\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d4d522-7214-4d93-b8c1-ec0a9d860df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the necessary imports\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Create a TruncatedSVD instance: svd\n",
    "svd = TruncatedSVD(n_components=50)\n",
    "\n",
    "# Create a KMeans instance: kmeans\n",
    "kmeans = KMeans(n_clusters=6)\n",
    "\n",
    "# Create a pipeline: pipeline\n",
    "pipeline = make_pipeline(svd, kmeans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df773760-d4d6-4a6c-8bf4-d8502fed6442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Fit the pipeline to articles\n",
    "pipeline.fit(articles)\n",
    "\n",
    "# Calculate the cluster labels: labels\n",
    "labels = pipeline.predict(articles)\n",
    "\n",
    "# Create a DataFrame aligning labels and titles: df\n",
    "df = pd.DataFrame({'label': labels, 'article': titles})\n",
    "\n",
    "# Display df sorted by cluster label\n",
    "print(df.sort_values(['label']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4c1222-0402-4806-a4f7-e7d25af68787",
   "metadata": {},
   "source": [
    "## Chapter 4: Discovering Interpretable Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f1ec87-2c2a-4a80-b6cf-31b10666f93e",
   "metadata": {},
   "source": [
    "### Non-negative matrix factorization (NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64592ae1-991f-42d6-9723-0ebd818993e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of NMF\n",
    "# samples is the word-frequency array\n",
    "from sklearn.decomposition import NMF\n",
    "model = NMF(n_components=2)\n",
    "model.fit(samples)\n",
    "NMF(n_components=2)\n",
    "nmf_features = model.transform(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7361b64f-b8f5-41de-b521-7bd8345f0484",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.components_)\n",
    "print(nmf_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fbee4b-4587-4135-9667-aca7ca928004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying NMF to the articles\n",
    "print(articles.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c10abd4-c541-4575-b408-d913f7891e0f",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fde8a74-2846-4e3b-8fb6-55c722d5f5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NMF\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# Create an NMF instance: model\n",
    "model = NMF(n_components=6)\n",
    "\n",
    "# Fit the model to articles\n",
    "model.fit(articles)\n",
    "\n",
    "# Transform the articles: nmf_features\n",
    "nmf_features = model.transform(articles)\n",
    "\n",
    "# Print the NMF features\n",
    "print(nmf_features.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d052de0a-c867-4d85-af82-862051b9fb89",
   "metadata": {},
   "source": [
    "## NMF learns interpretable parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d56a8e-65d2-41c6-b71d-d6bfe6d15427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "nmf = NMF(n_components=10)\n",
    "nmf.fit(articles)\n",
    "\n",
    "NMF(n_components=10)\n",
    "\n",
    "print(nmf.components_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a595e766-4343-4d1e-82c1-93418ec9c288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying to images\n",
    "bitmap = sample.reshape((2, 3))\n",
    "print(bitmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c8606c-583a-49f3-bc0b-e77d23440a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(bitmap, cmap='gray', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eae2f6-dcee-4b45-8644-186075b60293",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363058e8-322f-45f7-991b-8f29aa15a1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame: components_df\n",
    "components_df = pd.DataFrame(model.components_, columns=words)\n",
    "\n",
    "# Print the shape of the DataFrame\n",
    "print(components_df.shape)\n",
    "\n",
    "# Select row 3: component\n",
    "component = components_df.iloc[3]\n",
    "\n",
    "# Print result of nlargest\n",
    "print(component.nlargest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bdca5f-29d6-4e47-8f6f-0734c9548c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digit display image data example\n",
    "\n",
    "# Import pyplot\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Select the 0th row: digit\n",
    "digit = samples[0]\n",
    "\n",
    "# Print digit\n",
    "print(digit)\n",
    "\n",
    "# Reshape digit to a 13x8 array: bitmap\n",
    "bitmap = digit.reshape((13, 8))\n",
    "\n",
    "# Print bitmap\n",
    "print(bitmap)\n",
    "\n",
    "# Use plt.imshow to display bitmap\n",
    "plt.imshow(bitmap, cmap='gray', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6917ab-fab8-464e-ab68-ea6125d9f800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NMF\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# Create an NMF model: model\n",
    "model = NMF(n_components=7)\n",
    "\n",
    "# Apply fit_transform to samples: features\n",
    "features = model.fit_transform(samples)\n",
    "\n",
    "# Call show_as_image on each component\n",
    "for component in model.components_:\n",
    "    show_as_image(component)\n",
    "\n",
    "# Select the 0th row of features: digit_features\n",
    "digit_features = features[0]\n",
    "\n",
    "# Print digit_features\n",
    "print(digit_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332cb4a2-97bc-49e7-8a64-287d96246394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA doesn't learn parts\n",
    "\n",
    "# Import PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create a PCA instance: model\n",
    "model = PCA(n_components=7)\n",
    "\n",
    "# Apply fit_transform to samples: features\n",
    "features = model.fit_transform(samples)\n",
    "\n",
    "# Call show_as_image on each component\n",
    "for component in model.components_:\n",
    "    show_as_image(component)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f66db86-e826-4669-b00e-dec6f9c34563",
   "metadata": {},
   "source": [
    "## Building recommender systems using NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06d7beb-08a6-4d85-a894-b1365c48114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply NMF to the word-frequency array\n",
    "# articles is a word frequency array\n",
    "from sklearn.decomposition import NMF\n",
    "nmf = NMF(n_components=6)\n",
    "nmf_features = nmf.fit_transform(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12831783-89e9-4929-b490-42af68f417b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the cosine similarities\n",
    "from sklearn.preprocessing import normalize\n",
    "norm_features = normalize(nmf_features)\n",
    "# if has index 23\n",
    "current_article = norm_features[23,:]\n",
    "similarities = norm_features.dot(current_article)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cf141c-c35d-4920-a7c6-e8eac7aabadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrames and labels\n",
    "# Label similarities with the article titles, using a DataFrame\n",
    "# Titles given as a list: titles\n",
    "import pandas as pd\n",
    "norm_features = normalize(nmf_features)\n",
    "df = pd.DataFrame(norm_features, index=titles)\n",
    "current_article = df.loc['Dog bites man']\n",
    "similarities = df.dot(current_article)\n",
    "\n",
    "# DataFrames and labels\n",
    "print(similarities.nlargest())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e26e88f-5037-4a83-8769-ced94e10480e",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73015e08-3a5f-4856-a64a-adafe5c74423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the necessary imports\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Normalize the NMF features: norm_features\n",
    "norm_features = normalize(nmf_features)\n",
    "\n",
    "# Create a DataFrame: df\n",
    "df = pd.DataFrame(norm_features, index=titles)\n",
    "\n",
    "# Select the row corresponding to 'Cristiano Ronaldo': article\n",
    "article = df.loc['Cristiano Ronaldo']\n",
    "\n",
    "# Compute the dot products: similarities\n",
    "similarities = df.dot(article)\n",
    "\n",
    "# Display those with the largest cosine similarity\n",
    "print(similarities.nlargest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8a14b3-c418-4b95-91c0-f540f7d21558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the necessary imports\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import Normalizer, MaxAbsScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Create a MaxAbsScaler: scaler\n",
    "scaler = MaxAbsScaler()\n",
    "\n",
    "# Create an NMF model: nmf\n",
    "nmf = NMF(n_components=20)\n",
    "\n",
    "# Create a Normalizer: normalizer\n",
    "normalizer = Normalizer()\n",
    "\n",
    "# Create a pipeline: pipeline\n",
    "pipeline = make_pipeline(scaler, nmf, normalizer)\n",
    "\n",
    "# Apply fit_transform to artists: norm_features\n",
    "norm_features = pipeline.fit_transform(artists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae3314a-7a1b-45f2-bf15-30ef69e23afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame: df\n",
    "df = pd.DataFrame(norm_features, index=artist_names)\n",
    "\n",
    "# Select row of 'Bruce Springsteen': artist\n",
    "artist = df.loc['Bruce Springsteen']\n",
    "\n",
    "# Compute cosine similarities: similarities\n",
    "similarities = df.dot(artist)\n",
    "\n",
    "# Display those with highest cosine similarity\n",
    "print(similarities.nlargest())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
