{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0e78583-c98c-4b52-ac62-38217b4e1fb7",
   "metadata": {},
   "source": [
    "# Chapter 1: Introducing Image Processing and scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d9ab2a-f2d2-424f-b2c9-ad10cf468a8f",
   "metadata": {},
   "source": [
    "## Make images come alive with scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba41ea35-1a58-40fe-a50e-a3a1c049afef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images in scikit-image\n",
    "from skimage import data\n",
    "rocket_image = data.rocket()\n",
    "rocket_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d5740b-30b7-4c40-874f-aa2ebc345b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB vs Grayscale\n",
    "from skimage import color\n",
    "original = rocket_image\n",
    "grayscale = color.rgb2gray(original)\n",
    "rgb = color.gray2rgb(grayscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213f0b27-f892-4168-be0d-3e8084363c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing images in the course\n",
    "# Don't worry about Matplotlib!\n",
    "def show_image(image, title='Image', cmap_type='gray'):\n",
    "    plt.imshow(image, cmap=cmap_type)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e0a238-88fb-44a1-ade7-922b4b36a65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing images in the course\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import color\n",
    "# grayscale = color.rgb2gray(original)\n",
    "grayscale = color.rgb2gray(rocket_image)\n",
    "show_image(grayscale, \"Grayscale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72c55f5-7ffe-4c6d-9bbd-5aeadea30f89",
   "metadata": {},
   "source": [
    "## NumPy for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa337c5-06a9-4334-938e-43c36e8e896c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the image using Matplotlib\n",
    "madrid_image = plt.imread('/madrid.jpeg')\n",
    "type(madrid_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6d3057-8762-431b-95a2-c2f1b6e7a157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colors with NumPy\n",
    "# Obtaining the red values of the image\n",
    "red = image[:, :, 0]\n",
    "# Obtaining the green values of the image\n",
    "green = image[:, :, 1]\n",
    "# Obtaining the blue values of the image\n",
    "blue = image[:, :, 2]\n",
    "\n",
    "# Colors with NumPy\n",
    "plt.imshow(red, cmap=\"gray\")\n",
    "plt.title('Red')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c631ebca-426d-455a-ac5e-c0e418df88c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapes\n",
    "# Accessing the shape of the image\n",
    "madrid_image.shape\n",
    "# (426, 640, 3)\n",
    "\n",
    "# Sizes\n",
    "# Accessing the shape of the image\n",
    "madrid_image.size\n",
    "# 817920\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213382d0-73e8-4590-8313-833d7e84367e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flipping images: vertically\n",
    "# Flip the image in up direction\n",
    "vertically_flipped = np.flipud(madrid_image)\n",
    "show_image(vertically_flipped, 'Vertically flipped image')\n",
    "\n",
    "# Flipping images: horizontally\n",
    "# Flip the image in left direction\n",
    "horizontally_flipped = np.fliplr(madrid_image)\n",
    "show_image(horizontally_flipped, 'Horizontally flipped image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1785dc9f-e500-40fd-86fa-9da2878cfeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms in Matplotlib\n",
    "# Red color of the image\n",
    "red = image[:, :, 0]\n",
    "# Obtain the red histogram\n",
    "plt.hist(red.ravel(), bins=256)\n",
    "\n",
    "# Visualizing histograms with Matplotlib\n",
    "blue = image[:, :, 2]\n",
    "plt.hist(blue.ravel(), bins=256)\n",
    "plt.title('Blue Histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc74dbc-8700-4dc5-8030-9430f36cc8a5",
   "metadata": {},
   "source": [
    "## Getting started with thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3246462-acc7-4b57-a952-8c0705b2c2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply it\n",
    "# Obtain the optimal threshold value\n",
    "thresh = 127\n",
    "# Apply thresholding to the image\n",
    "binary = image > thresh\n",
    "# Show the original and thresholded\n",
    "show_image(image, 'Original')\n",
    "show_image(binary, 'Thresholded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e50887-b2ed-4bdb-bcf8-489468b34600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverted thresholding\n",
    "# Obtain the optimal threshold value\n",
    "thresh = 127\n",
    "# Apply thresholding to the image\n",
    "inverted_binary = image <= thresh\n",
    "# Show the original and thresholded\n",
    "show_image(image, 'Original')\n",
    "show_image(inverted_binary, 'Inverted thresholded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d672b4e6-78f3-4bbd-a9a4-bd9e41f248b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try more thresholding algorithms\n",
    "from skimage.filters import try_all_threshold\n",
    "# Obtain all the resulting images\n",
    "fig, ax = try_all_threshold(image, verbose=False)\n",
    "# Showing resulting plots\n",
    "show_plot(fig, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab441bd8-13cb-4ef3-b04c-59a23d51d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniform background\n",
    "# Import the otsu threshold function\n",
    "from skimage.filters import threshold_otsu\n",
    "# Obtain the optimal threshold value\n",
    "thresh = threshold_otsu(image)\n",
    "# Apply thresholding to the image\n",
    "binary_global = image > thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db011eae-982c-4338-a2a6-ccc0bccaf42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal thresh value\n",
    "# Global\n",
    "# Show the original and binarized image\n",
    "show_image(image, 'Original')\n",
    "show_image(binary_global, 'Global thresholding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f76fc07-61d2-4ed4-bb97-557f5c937d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal thresh value\n",
    "# Local\n",
    "# Uneven background\n",
    "# Import the local threshold function\n",
    "from skimage.filters import threshold_local\n",
    "# Set the block size to 35\n",
    "block_size = 35\n",
    "# Obtain the optimal local thresholding\n",
    "local_thresh = threshold_local(text_image, block_size, offset=10)\n",
    "# Apply local thresholding and obtain the binary image\n",
    "binary_local = text_image > local_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1bfcac-f80a-4f6b-bc02-0d9744e9c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal thresh value\n",
    "# Local\n",
    "# Show the original and binarized image\n",
    "show_image(text_image, 'Original')\n",
    "show_image(binary_local, 'Local thresholding')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e49f6e5-48d8-40d6-a55c-de5bcdf49316",
   "metadata": {},
   "source": [
    "# Chapter 2: Filters, Contrast, Transformation and Morphology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2461da4-cc16-407c-90f5-d8f176f30179",
   "metadata": {},
   "source": [
    "## Jump into filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cd0c29-aafb-4c67-a2aa-3df5eba97b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge detection\n",
    "# Sobel\n",
    "# Import module and function\n",
    "from skimage.filters import sobel\n",
    "# Apply edge detection filter\n",
    "edge_sobel = sobel(image_coins)\n",
    "# Show original and resulting image to compare\n",
    "plot_comparison(image_coins, edge_sobel, \"Edge with Sobel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6d2897-8de3-4f45-9009-aaa7af896bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing plots\n",
    "def plot_comparison(original, filtered, title_filtered):\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(8, 6), sharex=True, sharey=True)\n",
    "    ax1.imshow(original, cmap=plt.cm.gray)\n",
    "    ax1.set_title('original')\n",
    "    ax1.axis('off')\n",
    "    ax2.imshow(filtered, cmap=plt.cm.gray)\n",
    "    ax2.set_title(title_filtered)\n",
    "    ax2.axis('off')\n",
    "\n",
    "# Gaussian smoothing\n",
    "# Import the module and function\n",
    "from skimage.filters import gaussian\n",
    "# Apply edge detection filter\n",
    "gaussian_image = gaussian(amsterdam_pic, multichannel=True)\n",
    "# Show original and resulting image to compare\n",
    "plot_comparison(amsterdam_pic, gaussian_image, \"Blurred with Gaussian filter\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9496a2-91b8-4401-bfcb-0bcfd44f21d6",
   "metadata": {},
   "source": [
    "## Contrast enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04329dac-28a4-4485-8713-c93d2b35dae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram equalization\n",
    "from skimage import exposure\n",
    "# Obtain the equalized image\n",
    "image_eq = exposure.equalize_hist(image)\n",
    "# Show original and result\n",
    "show_image(image, 'Original')\n",
    "show_image(image_eq, 'Histogram equalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4085291-918a-4689-bebf-fa652ab40480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAHE in scikit-image\n",
    "from skimage import exposure\n",
    "# Apply adaptive Equalization\n",
    "image_adapteq = exposure.equalize_adapthist(image, clip_limit=0.03)\n",
    "# Show original and result\n",
    "show_image(image, 'Original')\n",
    "show_image(image_adapteq, 'Adaptive equalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5328eeff-1124-485b-90e2-bb58716b4736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotating clockwise\n",
    "from skimage.transform import rotate\n",
    "# Rotate the image 90 degrees clockwise\n",
    "image_rotated = rotate(image, -90)\n",
    "show_image(image, 'Original')\n",
    "show_image(image_rotated, 'Rotated 90 degrees clockwise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d4b3eb-546f-4ed4-8883-e2dfd1fdadac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotating anticlockwise\n",
    "from skimage.transform import rotate\n",
    "# Rotate an image 90 degrees anticlockwise\n",
    "image_rotated = rotate(image, 90)\n",
    "show_image(image, 'Original')\n",
    "show_image(image_rotated, 'Rotated 90 degrees anticlockwise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70427345-2238-43d7-8085-77afbe67d15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescaling\n",
    "# Downgrading\n",
    "from skimage.transform import rescale\n",
    "# Rescale the image to be 4 times smaller\n",
    "image_rescaled = rescale(image, 1/4, anti_aliasing=True, multichannel=True)\n",
    "show_image(image, 'Original image')\n",
    "show_image(image_rescaled, 'Rescaled image')\n",
    "\n",
    "# Resizing\n",
    "from skimage.transform import resize\n",
    "# Height and width to resize\n",
    "height = 400\n",
    "width = 500\n",
    "# Resize image\n",
    "image_resized = resize(image, (height, width), anti_aliasing=True)\n",
    "# Show the original and resulting images\n",
    "show_image(image, 'Original image')\n",
    "show_image(image_resized, 'Resized image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3e3907-2f9c-4111-80cd-55d50282a39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing proportionally\n",
    "from skimage.transform import resize\n",
    "# Set proportional height so its 4 times its size\n",
    "height = image.shape[0] / 4\n",
    "width = image.shape[1] / 4\n",
    "# Resize image\n",
    "image_resized = resize(image, (height, width), anti_aliasing=True)\n",
    "show_image(image_resized, 'Resized image')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb07813-e876-4ce7-b09f-5fc232063e10",
   "metadata": {},
   "source": [
    "## Morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee8d03a-b80c-4ac9-8646-d2de8f18b3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapes in scikit-image\n",
    "from skimage import morphology\n",
    "rectangle = morphology.rectangle(4, 2)\n",
    "square = morphology.square(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105774c3-fde9-4857-8f5a-dfbad69c8234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erosion in scikit-image\n",
    "from skimage import morphology\n",
    "# Set structuring element to the rectangular-shaped\n",
    "selem = rectangle(12,6)\n",
    "# Obtain the erosed image with binary erosion\n",
    "eroded_image = morphology.binary_erosion(image_horse, selem=selem)\n",
    "\n",
    "# Erosion in scikit-image\n",
    "# Show result\n",
    "plot_comparison(image_horse, eroded_image, 'Erosion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6bf2fc-2d8f-4cd9-9ea5-cb0cbfc3ff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary erosion with default selem\n",
    "# Binary erosion with default selem\n",
    "eroded_image = morphology.binary_erosion(image_horse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e789bd-8c6b-4d92-8ebc-23cc2002a700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dilation in scikit-image\n",
    "from skimage import morphology\n",
    "# Obtain dilated image, using binary dilation\n",
    "dilated_image = morphology.binary_dilation(image_horse)\n",
    "# See results\n",
    "plot_comparison(image_horse, dilated_image, 'Erosion')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5349bc-4da5-42ab-97c7-587341ea8246",
   "metadata": {},
   "source": [
    "# Chapter 3: Image restoration, Noise, Segmentation and Contours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ad9322-c98e-4ed4-8174-daf5eed935d5",
   "metadata": {},
   "source": [
    "## Image restoration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacf198c-4c9a-4cd1-8d8f-c39f885a580c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image reconstruction in scikit-image\n",
    "from skimage.restoration import inpaint\n",
    "# Obtain the mask\n",
    "mask = get_mask(defect_image)\n",
    "# Apply inpainting to the damaged image using the mask\n",
    "restored_image = inpaint.inpaint_biharmonic(\n",
    "    defect_image, mask, multichannel=True\n",
    ")\n",
    "# Show the resulting image\n",
    "show_image(restored_image)\n",
    "\n",
    "# Image reconstruction in scikit-image\n",
    "# Show the defect and resulting images\n",
    "show_image(defect_image, 'Image to restore')\n",
    "show_image(restored_image, 'Image restored')\n",
    "\n",
    "# Masks\n",
    "def get_mask(image):\n",
    "    ''' Creates mask with three defect regions '''\n",
    "    mask = np.zeros(image.shape[:-1])\n",
    "    mask[101:106, 0:240] = 1\n",
    "    mask[152:154, 0:60] = 1\n",
    "    mask[153:155, 60:100] = 1\n",
    "    mask[154:156, 100:120] = 1\n",
    "    mask[155:156, 120:140] = 1\n",
    "    mask[212:217, 0:150] = 1\n",
    "    mask[217:222, 150:256] = 1\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795b45bd-7f8d-46e5-9c64-b1796fb18489",
   "metadata": {},
   "source": [
    "## Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974f2619-b147-479d-9038-59ef6e3f71cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply noise in scikit-image\n",
    "# Import the module and function\n",
    "from skimage.util import random_noise\n",
    "# Add noise to the image\n",
    "noisy_image = random_noise(dog_image)\n",
    "# Show original and resulting image\n",
    "show_image(dog_image)\n",
    "show_image(noisy_image, 'Noisy image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d29b797-bede-4ac0-8098-a0f86d79e817",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Denoising\n",
    "#Using total variation filter denoising\n",
    "from skimage.restoration import denoise_tv_chambolle\n",
    "# Apply total variation filter denoising\n",
    "denoised_image = denoise_tv_chambolle(\n",
    "    noisy_image, weight=0.1, multichannel=True\n",
    ")\n",
    "# Show denoised image\n",
    "show_image(noisy_image, 'Noisy image')\n",
    "show_image(denoised_image, 'Denoised image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfd621e-fa5a-4be3-830e-07e7478d1a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Denoising\n",
    "#Bilateral filter\n",
    "from skimage.restoration import denoise_bilateral\n",
    "# Apply bilateral filter denoising\n",
    "denoised_image = denoise_bilateral(noisy_image, multichannel=True)\n",
    "# Show original and resulting images\n",
    "show_image(noisy_image, 'Noisy image')\n",
    "show_image(denoised_image, 'Denoised image')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8f82d3-2009-438c-843b-3e1b33e32eb5",
   "metadata": {},
   "source": [
    "## Superpixels & segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81e0d32-4ac5-44a4-801d-8eda866cf68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unsupervised segmentation (SLIC)\n",
    "# Import the modules\n",
    "from skimage.segmentation import slic\n",
    "from skimage.color import label2rgb\n",
    "# Obtain the segments\n",
    "segments = slic(image)\n",
    "# Put segments on top of original image to compare\n",
    "segmented_image = label2rgb(segments, image, kind='avg')\n",
    "show_image(image)\n",
    "show_image(segmented_image, \"Segmented image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb78a8c7-e6d8-450a-a0d2-82b6f5cd60f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#More segments\n",
    "# Import the modules\n",
    "from skimage.segmentation import slic\n",
    "from skimage.color import label2rgb\n",
    "# Obtain the segmentation with 300 regions\n",
    "segments = slic(image, n_segments= 300)\n",
    "# Put segments on top of original image to compare\n",
    "segmented_image = label2rgb(segments, image, kind='avg')\n",
    "show_image(segmented_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0382b78e-da77-4da5-b8e4-0f1a285aedbc",
   "metadata": {},
   "source": [
    "## Finding contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1a991c-0489-41b1-996c-e83bcae17223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find contours using scikit-image\n",
    "# PREPARING THE IMAGE\n",
    "# Transform the image to 2D grayscale.\n",
    "# Make the image grayscale\n",
    "image = color.rgb2gray(image)\n",
    "\n",
    "# Find contours using scikit-image\n",
    "# PREPARING THE IMAGE\n",
    "# Binarize the image\n",
    "# Obtain the thresh value\n",
    "thresh = threshold_otsu(image)\n",
    "# Apply thresholding\n",
    "thresholded_image = image > thresh\n",
    "\n",
    "# Find contours using scikit-image\n",
    "# And then use find_contours().\n",
    "# Import the measure module\n",
    "from skimage import measure\n",
    "# Find contours at a constant value of 0.8\n",
    "contours = measure.find_contours(thresholded_image, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3b3910-7232-481a-8206-86c69faf7fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The steps to spotting contours\n",
    "from skimage import measure\n",
    "from skimage.filters import threshold_otsu\n",
    "# Make the image grayscale\n",
    "image = color.rgb2gray(image)\n",
    "# Obtain the optimal thresh value of the image\n",
    "thresh = threshold_otsu(image)\n",
    "# Apply thresholding and obtain binary image\n",
    "thresholded_image = image > thresh\n",
    "# Find contours at a constant value of 0.8\n",
    "contours = measure.find_contours(thresholded_image, 0.8)\n",
    "\n",
    "# A contour's shape\n",
    "# Contours: list of (n,2) - ndarrays.\n",
    "for contour in contours:\n",
    "    print(contour.shape)\n",
    "\n",
    "# A contour's shape\n",
    "for contour in contours:\n",
    "    print(contour.shape)\n",
    "\n",
    "# A contour's shape\n",
    "for contour in contours:\n",
    "    print(contour.shape)\n",
    "\n",
    "# A contour's shape\n",
    "for contour in contours:\n",
    "    print(contour.shape)\n",
    "\n",
    "# A contour's shape\n",
    "for contour in contours:\n",
    "    print(contour.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9c1329-ba13-49c4-90b7-0e579dee0930",
   "metadata": {},
   "source": [
    "# Chapter 4: Advanced Operations, Detecting Faces and Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671b5c28-031a-44e1-be90-a580b248444d",
   "metadata": {},
   "source": [
    "## Finding the edges with Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4f185d-14ca-44a6-954d-f90cb51ef714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge detection\n",
    "from skimage.feature import canny\n",
    "# Convert image to grayscale\n",
    "coins = color.rgb2gray(coins)\n",
    "# Apply Canny detector\n",
    "canny_edges = canny(coins)\n",
    "# Show resulted image with edges\n",
    "show_image(canny_edges, \"Edges with Canny\")\n",
    "\n",
    "# Canny edge detector\n",
    "# Apply Canny detector with a sigma of 0.5\n",
    "canny_edges_0_5 = canny(coins, sigma=0.5)\n",
    "# Show resulted images with edges\n",
    "show_image(canny_edges, \"Sigma of 1\")\n",
    "show_image(canny_edges_0_5, \"Sigma of 0.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19c29c6-a532-47ee-8a3a-2b8ab194d719",
   "metadata": {},
   "source": [
    "## Right around the corner\n",
    "* Corner detection\n",
    "* Points of interest are invariant under rotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93f123d-3a3b-466a-abd5-23a428ba78cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harris corner detector\n",
    "from skimage.feature import corner_harris\n",
    "# Convert image to grayscale\n",
    "image = rgb2gray(image)\n",
    "# Apply the Harris corner detector on the image\n",
    "measure_image = corner_harris(image)\n",
    "# Show the Harris response image\n",
    "show_image(measure_image)\n",
    "\n",
    "# Harris corner detector\n",
    "# Finds the coordinates of the corners\n",
    "coords = corner_peaks(corner_harris(image), min_distance=5)\n",
    "print(\"A total of\", len(coords), \"corners were detected.\")\n",
    "# A total of 122 corners were found from measure response image.\n",
    "\n",
    "# Corners detected\n",
    "# Show image with marks in detected corners\n",
    "show_image_with_corners(image, coords)\n",
    "show_image_with_detected_corners\n",
    "# Show image with contours\n",
    "def show_image_with_corners(image, coords, title=\"Corners detected\"):\n",
    "    plt.imshow(image, interpolation='nearest', cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.plot(coords[:, 1], coords[:, 0], '+r', markersize=15)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb15886-fcd1-4800-b75e-47dc1a3523da",
   "metadata": {},
   "source": [
    "## Face detection\n",
    "\n",
    "Face detection use cases\n",
    "* Filters\n",
    "* Auto focus\n",
    "* Recommendations\n",
    "* Blur for privacy protection\n",
    "* To recognize emotions later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840a4670-3b04-4cfc-893d-6d06c44626e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting faces with scikit-image\n",
    "# Import the classifier class\n",
    "from skimage.feature import Cascade\n",
    "# Load the trained file from the module root.\n",
    "trained_file = data.lbp_frontal_face_cascade_filename()\n",
    "# Initialize the detector cascade.\n",
    "detector = Cascade(trained_file)\n",
    "\n",
    "# Detecting faces\n",
    "# Apply detector on the image\n",
    "detected = detector.detect_multi_scale(\n",
    "    img=image, scale_factor=1.2, step_ratio=1,\n",
    "    min_size=(10, 10), max_size=(200, 200)\n",
    ")\n",
    "\n",
    "# Detected faces\n",
    "print(detected)\n",
    "# Show image with detected face marked\n",
    "show_detected_face(image, detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01e7009-9bef-45a5-a22c-f6654d6bbe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show detected faces\n",
    "def show_detected_face(result, detected, title=\"Face image\"):\n",
    "    plt.imshow(result)\n",
    "    img_desc = plt.gca()\n",
    "    plt.set_cmap('gray')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    for patch in detected:\n",
    "        img_desc.add_patch(\n",
    "            patches.Rectangle(\n",
    "                (patch['c'], patch['r']),\n",
    "                patch['width'],\n",
    "                patch['height'],\n",
    "                fill=False,\n",
    "                color='r',\n",
    "                linewidth=2\n",
    "            )\n",
    "        )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6c10e5-5357-4dec-a51e-083b42dc0315",
   "metadata": {},
   "source": [
    "## Real-world applications\n",
    "\n",
    "Applications\n",
    "* Turning to grayscale before detecting edges/corners\n",
    "* Reducing noise and restoring images\n",
    "* Blurring faces detected\n",
    "* Approximation of objects' sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714b2774-1e4b-4602-a5a0-6fab9728cedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Privacy protection\n",
    "# Import Cascade of classifiers and gaussian filter\n",
    "from skimage.feature import Cascade\n",
    "from skimage.filters import gaussian\n",
    "\n",
    "# Privacy protection\n",
    "# Detect the faces\n",
    "detected = detector.detect_multi_scale(\n",
    "    img=image, scale_factor=1.2, step_ratio=1, min_size=(50, 50), max_size=(100, 100)\n",
    ")\n",
    "# For each detected face\n",
    "for d in detected:\n",
    "    # Obtain the face cropped from detected coordinates\n",
    "    face = getFace(d)\n",
    "\n",
    "# Privacy protection\n",
    "def getFace(d):\n",
    "    ''' Extracts the face rectangle from the image using the\n",
    "    coordinates of the detected.'''\n",
    "    # X and Y starting points of the face rectangle\n",
    "    x, y = d['r'], d['c']\n",
    "\n",
    "    # The width and height of the face rectangle\n",
    "    width, height = d['r'] + d['width'], d['c'] + d['height']\n",
    "    \n",
    "    # Extract the detected face\n",
    "    face= image[x:width, y:height]\n",
    "    return face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d4773c-1612-4c21-92aa-9bf2e5b620ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Privacy protection\n",
    "# Detect the faces\n",
    "detected = detector.detect_multi_scale(\n",
    "    img=image,\n",
    "    scale_factor=1.2, step_ratio=1,\n",
    "    min_size=(50, 50), max_size=(100, 100)\n",
    ")\n",
    "# For each detected face\n",
    "for d in detected:\n",
    "    # Obtain the face cropped from detected coordinates\n",
    "    face = getFace(d)\n",
    "    # Apply gaussian filter to extracted face\n",
    "    gaussian_face = gaussian(face, multichannel=True, sigma = 10)\n",
    "    # Merge this blurry face to our final image and show it\n",
    "    resulting_image = mergeBlurryFace(image, gaussian_face)\n",
    "\n",
    "# Privacy protection\n",
    "# NOTE (JS): `d` is used in the following, so this function signature probably needs to be improved\n",
    "def mergeBlurryFace(original, gaussian_image):\n",
    "    # X and Y starting points of the face rectangle\n",
    "    x, y = d['r'], d['c']\n",
    "\n",
    "    # The width and height of the face rectangle\n",
    "    width, height = d['r'] + d['width'],  d['c'] + d['height']\n",
    "    original[x:width, y:height] = gaussian_image\n",
    "    return original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7853e474-8ba4-47cc-89f4-1f74b44e94e2",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6926ec89-72a5-4ee0-9b96-0c840bc03f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "from skimage.restoration import denoise_tv_chambolle, inpaint\n",
    "from skimage import transform\n",
    "\n",
    "# Transform the image so it's not rotated\n",
    "upright_img = rotate(damaged_image, 20)\n",
    "\n",
    "# Remove noise from the image, using the chambolle method\n",
    "upright_img_without_noise = denoise_tv_chambolle(upright_img,weight=0.1, multichannel=True)\n",
    "\n",
    "# Reconstruct the image missing parts\n",
    "mask = get_mask(upright_img)\n",
    "result = inpaint.inpaint_biharmonic(upright_img_without_noise, mask, multichannel=True)\n",
    "\n",
    "show_image(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
